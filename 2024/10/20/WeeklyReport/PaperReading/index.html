<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>PaperReading | 11的Blog</title><meta name="keywords" content="论文,组会汇报"><meta name="author" content="11andyy"><meta name="copyright" content="11andyy"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="PaperReading"><meta name="application-name" content="PaperReading"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="PaperReading"><meta property="og:url" content="https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/index.html"><meta property="og:site_name" content="11的Blog"><meta property="og:description" content="基于神经网络的惯性导航定位    论文 场景 网络 期刊&amp;#x2F;会议 代码     IONet: Learning to Cure the Curse of Drift in Inertial Odometry Pedestrian LSTM 2018 AAAI    RIDI: Robust IMU"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png"><meta property="article:author" content="11andyy"><meta property="article:tag" content="11的Blog"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png"><meta name="description" content="基于神经网络的惯性导航定位    论文 场景 网络 期刊&amp;#x2F;会议 代码     IONet: Learning to Cure the Curse of Drift in Inertial Odometry Pedestrian LSTM 2018 AAAI    RIDI: Robust IMU"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: {"enable":true,"title":"与数百名博主无限进步","addFriendPlaceholder":"昵称（请勿包含博客等字样）：\n网站地址（要求博客地址，请勿提交个人主页）：\n头像图片url（请提供尽可能清晰的图片，我会上传到我自己的图床）：\n描述：\n站点截图（可选）：\n"},
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"tianli","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"不要走！再看看嘛！","backTitle":"欢迎肥来！"},
  LA51: undefined,
  greetingBox: {"enable":true,"default":"晚上好👋","list":[{"greeting":"晚安😴","startTime":0,"endTime":5},{"greeting":"早上好鸭👋, 祝你一天好心情！","startTime":6,"endTime":9},{"greeting":"上午好👋, 状态很好，鼓励一下～","startTime":10,"endTime":10},{"greeting":"11点多啦, 在坚持一下就吃饭啦～","startTime":11,"endTime":11},{"greeting":"午安👋, 小猪","startTime":12,"endTime":14},{"greeting":"🌈充实的一天辛苦啦！","startTime":14,"endTime":18},{"greeting":"19点喽, 奖励一顿丰盛的大餐吧🍔。","startTime":19,"endTime":19},{"greeting":"晚上好👋, 在属于自己的时间好好放松😌~","startTime":20,"endTime":24}]},
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  root: '/',
  preloader: {"source":3},
  friends_vue_info: {"apiurl":null},
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🏠 智能家居小能手","🔨 设计开发一条龙","🤝 专修交互与设计","🏃 脚踏实地行动派","🧱 团队小组发动机","💢 壮汉人狠话不多"]},
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: 11andyy","link":"链接: ","source":"来源: 11的Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: {"enable":true,"delay":100,"shiftDelay":200},
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '11的Blog',
  title: 'PaperReading',
  postAI: '',
  pageFillDescription: '基于神经网络的惯性导航定位, IONet Learning to Cure the Curse of Drift in Inertial Odometry, 基本内容, 摘要, 相关工作, 主要内容, 惯性跟踪, 按窗口切分惯性数据, 位移, 偏航角, 深度学习网络框架, 实验, 数据集, 训练, RIDI Robust IMU Double Integration, 基本内容, 摘要, 相关工作, 主要内容, 坐标系, 学习回归速度, 修正加速度误差, 实验, RINS-W Robust Inertial Navigation System on Wheels, 基本内容, 摘要, 相关工作, 主要内容, 惯性导航系统和传感器模型, 惯性导航系统, IMU模型, 轮式机器人运动特性, 轮式机器人运动轮廓, 轮式机器人运动轮廓的选择, RINS-W算法, 特定的运动轮廓检测器（LSTM）, 不变扩展卡尔曼滤波器（IEKF）, Car Datasets数据集, 实验, RoNIN Robust Neural Inertial Navigation in the Wild Benchmark Evaluations and New Methods, 基本内容, 摘要, 相关工作, 主要内容, RONIN数据集, RoNIN网络, 坐标系归一化, Backbone网络结构, 鲁棒速度损失, RoNIN身体航向网络, 实验, 评估, 位置评估, 航向评估, AI-IMU Dead-Reckoning, Neural Inertial Localization, 基本内容, 摘要, 相关工作, 主要内容, 惯性定位问题, 惯性定位数据集, NILoc神经惯性定位, 速度分支, 自回归位置分支, 合成数据生成, 实验, Deep Learning Based Speed Estimation for Constraining Strapdown Inertial Navigation on Smartphones, TLIO Tight Learned Inertial Odometry, Template, 基本内容, 摘要, 相关工作, 主要内容, 实验基于神经网络的惯性导航定位论文场景网络期刊会议代码基本内容作者主页未开源论文摘要应用背景惯性传感器的室内定位面临问题惯性传感器的加速度输出当对加速度二重积分后得到位移误差会增大解决方案不采用二重积分将惯性数据切分成一个个窗口估计每一个窗口内物体的速度和方向具体实现通过深度递归神经网络输入原始的序列数据输出得到完整的高精度轨迹贡献通过牛顿力学推导出基于序列的物理模型将惯性跟踪问题转为顺序学习问题首个深度神经网络从原始的输出数据学习极坐标的位置变换论证了模型还可以推广到一般的非周期性的运动比如婴儿车时走时停相关工作捷联惯性导航系统行人航位推算使用惯性测量来检测步骤通过经验公式估计步幅长度和航向但是动态步长估计受到传感器噪声的影响还需要根据用户的运动习惯仔细调整大量参数序列的深度学习视觉里程计本文提出首个仅使用惯性数据实现的惯性里程计主要内容惯性跟踪姿态更新角速度测量从到时刻利用测量得到物体的角速度即三个轴上的角速度旋转角度计算角速度与时间微元相乘得到微小的角度旋转量构建相对旋转矩阵利用生成相对旋转矩阵表示物体从时刻到时刻的相对变换该公式源自旋转公式相对旋转矩阵表示载体坐标系就是的坐标从时刻到时刻的变换其中表示角度的叉积矩阵如果叉积矩阵可以表示为这里的都是标量计算第一项单位矩阵第二项线性项表示旋转的初始变化第三项非线性项描述旋转角度增加时的高阶影响当旋转角度很小时可以简化为更简单的线性关系更新方向余弦矩阵将上一刻的方向余弦矩阵和相对旋转矩阵相乘得到当前的方向余弦矩阵我的理解时刻载体系到导航坐标系的变换时刻载体系到导航坐标系的变换从时刻到时刻载体系的变换该更新公式表示物体姿态的累积变化使导航系统能够跟踪物体在三维空间中的连续姿态变化速度更新对速度的更新实际上就是计算比力然后对比力进行积分这里都是向量形式获取加速度的测量值从获取载体坐标系下的加速度计算导航坐标系下的比力将加速度从载体坐标系转换到导航坐标系为什么用积分更新速度位置更新对位置的更新实际上就是对速度积分面临两大问题噪声初始化时间久不适用行人轨迹跟踪任务按窗口切分惯性数据按照窗口切分惯性数据估计每个窗口的姿态速度位置是不合理的因为每个窗口的数据并不是独立的当前的状态需要从上一个状态推导得到因此目标是伪独立性估计每个窗口的导航状态变化遵循这一思想我们从运动的基本牛顿定律推导出一种新的基于序列的物理模型并将其重新表述为学习模型位移传统的惯导系统可以用下述公式来表述计算位移在个窗口内的变化将这个总位移看成两部分的和相加一部分是初始速度的在时间内的累积贡献另一部分是每一段的加速度对时间的累积贡献这个公式特别像上述总位移公式可以进一步推导为需要结合前面的姿态更新的计算进一步简化为因为考虑的室内定位问题认为导航坐标系中是没有变化的因此计算位移的二范数注意这里的速度测得的是相对于载体坐标系的速度重力加速度也是相对于载体坐标系的然后借助方向余弦矩阵转换到导航坐标系中由于方向余弦矩阵为正交矩阵有在计算位移的二范数时可以消掉因此哪怕我们不知道初始的位姿我们也能计算得到位移因此在窗口内行进的水平距离可以表示为初始速度重力和线加速度和角加速度的函数所有这些都在载体坐标系的框架中偏航角如何通过惯性测量单元获取的原始数据来确定用户在水平面上的航向角并最终将传统模型转换为基于极坐标表示的模型载体真实的加速度和角速度是的测量数据的隐含变量的原始数据包含了一些噪声和偏差而真正的加速度和角速度是隐含在这些测量数据中的需要进一步处理才能得到真实值由于系统是在水平面上运动因此姿态角翻滚俯仰偏航只有偏航角是关键的参数换句话说系统只关注用户在水平面上的旋转角度根据公式和可以将偏航角表示为测量数据的函数提取积分后的第三个分量利用原始数据来估计航向变化起始位置和终止位置的关系可以写为其中是初始位置是初始偏航角问题变为了如何通过将每个窗口转换为序列学习问题来隐式估计载体帧中的这种初始速度和重力深度学习网络框架输入每个窗口连续的数据本体坐标系下的加速度和角速度输出每个窗口估计的导航坐标系下物体的位移和偏转角将此公式作为一个序列输入是传感器观测到的数据输出是极坐标向量输入数据每个窗口连续的数据测量被分成步长为帧的独立窗口输出数据极坐标向量网络两层第一层的输出序列提供了第二层的输入序列第二个输出一个极坐标向量来表示处理后的序列中的变换关系最优参数可以通过最小化训练集上的损失函数来恢复损失函数的和估计值的欧氏距离是调节权重位移和偏航角哪个影响更大的因子实验数据集没有公共数据集用于使用基于手机的进行室内定位训练数据集由来自不同附件的手机的数据组成例如手持在口袋里手袋里每个拖车小时由收集训练框架优化器个后收敛每个层不同用户不同设备基本内容作者主页论文摘要应用背景仅从每个智能手机中的惯性测量单元估计人体运动的轨迹面临问题对速度双积分导致误差爆炸手机的旋转和人的步行方向并不是完全重合的解决方案具体实现从历史观测的加速度和角速度回归速度向量纠正加速度中的低频误差以与回归的速度兼容再使用标准的双积分从校正后的加速度来估计轨迹输入相对于坐标系的的加速度和角速度序列输出相对于坐标系的二维速度向量贡献和纯视觉惯性导航效果相当数据驱动的惯性导航的第一篇工作产生与地面实况相当的运动轨迹平均位置误差低于相关工作视觉基于的旋转估计很成功被用于设备基于的位置跟踪主要内容前提地板平坦回归和位置估计是在二维平面上运行的鲁棒双积分分为三步从角速度和加速度回归速度向量估计加速度的低频修正使其积分的速度与回归的速度值相匹配对校正后的加速度进行双积分以估计位置坐标系在该算法中考虑三个坐标系世界坐标系在世界坐标系中估计输出位置被设置为第一帧的全局坐标系设备坐标系和重力方向平行的一个坐标系图中绿色这个坐标系使得回归任务变得简单因为回归于设备的倾斜和滚动无关学习回归速度在坐标系中学习回归速度对于每个训练的序列我们先将设备的姿态相对于以及设备的加速度和角速度相对于都转换到相对于坐标系为了抑制高频噪声使用的高斯平滑应用于六个输出量使用应用于回归的两个速度分量上方向方向将历时帧的角速度和线性加速度连接起来构造维特征向量人们会用不同的方式携带手机在口袋包里手持在身上充分利用这些知识构造了一个级联的回归模型先通过进行分类然后通过两个单独的对速度的两个分量进行回归速度只有水平方向的速度和超参数修正加速度误差预测速度在去除传感器噪声和偏差方面提供了有效的线索我们做了一个简化的假设将所有的误差建模为线性加速度的低频误差绕过了显示的误差建模转而将问题转化为简单的最小二乘问题对坐标系的加速度偏差进行建模将偏差表示为在采样帧处校正项的线性插值为了对这种低频偏差进行建模作者假设偏差在采样帧上是线性变化的每隔帧设置一个偏差修正项减少计算量例如是第帧的加速度偏差它的值是通过第帧和第帧的偏差修正项计算出来的权重和是根据第帧在第帧和第帧之间的位置比例计算出来的目标是最小化子采样帧集合内两个速度之间的差异来优化子采样帧集合内的各个而不是对每一帧都这样处理下面两个速度是相对于坐标系来定义的修正后的速度通过修正线性加速度积分后得到的速度回归速度通过回归得到的速度该优化问题第一项最小化这两个速度差异确保回归值更接近速度的真实值第二项正则化项约束修正项不要变化过于剧烈修正的速度计算先对加速度进行修正相对于坐标系的每一帧的加速度加上修正的偏差将坐标系下的加速度转到世界坐标系下的加速度然后进行积分得到速度再将这个速度转移到稳定的坐标系坐标系下实验基本内容作者主页论文摘要应用背景使用进行长期惯性导航的实时方法用于轮式机器人面临问题解决方案具体实现一种鲁棒检测器使用循环神经网络动态检测各种感兴趣的情况比如零速度横向偏移一种最先进的卡尔曼滤波器将知识作为定位的伪测量贡献在公开数据集上可以实现长距离轨迹大于的最终精度第一篇将深度学习技术和滤波方法结合的论文用于轮式车辆纯惯性导航该方法不仅限于基于的导航可以将卡尔曼滤波器与其他传感器的测量输入相关工作使用惯性传感器和视觉惯性系统的里程计与定位车辆约束的使用以提高定位的鲁棒性零速度更新自适应卡尔曼滤波主要内容惯性导航系统和传感器模型惯性导航系统假定的方向旋转矩阵是将坐标从载体坐标系映射到世界坐标系表示第帧在世界坐标系下的速度表示第帧在世界坐标系下的位置惯性导航系统模型可以写为为初始值在应用场景中忽略地球自转和科里奥利力即认为地球是平坦的模型对于的建模的测量值真实值偏置噪声为零偏为均值高斯噪声偏置遵循随机游动下一帧的偏置等于上一帧的偏置噪声轮式机器人运动特性轮式机器人运动轮廓考虑四种不同的运动状态其有效性用来进行编码零速度状态零速度状态满足两个约束即速度为比力为零角速度状态零侧向速度可以对速度进行分解前向横向垂向速度零垂直速度零侧向速度和零垂直速度是轮式机器人在常见道路形式的一般性假设轮式机器人运动轮廓的选择算法从中恢复轨迹和传感器偏差估计检测器是递归神经网络从原始信号估计二进制向量判断是哪一个速度状态从原始信号识别特定运动轮廓滤波器在动力学模型集成测量值利用检测到的运动轮廓作为伪测量来细化估计检测器不使用滤波器的输出而是独立使用原始信号进行训练特定的运动轮廓检测器检测器在每个时刻检测物体处于哪一个运动状态所用每种运动状态的概率分布是一个四维向量神经网络的隐藏状态然后将概率分数转为二进制向量每种运动状态都有一个概率的阈值超过则定为不变扩展卡尔曼滤波器使用执行的测量与检测到的特定运动轮廓之间的融合输出状态包括的姿态速度偏置及其协方差的状态包括机器人的姿态速度和的偏差前面提到的机器人的各种运动状态适用于右方法将线性状态误差定义为误差状态向量描述导航系统状态的误差例如姿态速度位置的误差表示传感器偏置误差包括加速度计和陀螺仪的偏置该误差向量服从均值协方差矩阵的正态分布使用分块向量结构包括姿态误差速度误差位置误差包括陀螺仪偏置误差和加速度计偏置误差下面的公式通过李群上的指数映射将误差与估计状态组合得到真实状态传感器的真实偏置可以分解为滤波器的估计值误差传播步骤如果没有检测到特定的运动状态使用模型获取状态并使用方程得到协方差如果检测到特定的运动状态每个运动轮廓产生下列伪测量数据集实验基本内容作者主页论文摘要应用背景仅从传感器测量序列估计运动物体的位置和方向不是设备的位置和方向而是运动物体的位置和方向面临问题现有的惯性导航算法都需要一些不切实际的约束必须放到脚上步骤计数方法假设刚性附着在身体上主体必须向前行走使运动方向在设备坐标系中变为常数解决方案数据驱动的方法传感器数据和地面轨迹真值允许运动参数的监督学习具体实现贡献新的数据集为的传感器数据提供真实的轨迹新的鲁棒神经惯导架构在具有挑战性的运动情况中有显著改进在三个上进行了定性和定量的评估相关工作对惯性导航算法进行归类没有先验对比力双积分得到位置对角速度积分得到偏转角面临的问题则是双积分会导致误差漂移非常严重启发式先验人的运动是比较规律的试图找到这种运动规律比如步骤计数的方法但是有约束且鲁棒性很差刚性附着于身体上运动方向相对于是固定的运动距离跟步数是成正比的数据驱动两个工作在载体坐标系中对速度向量进行回归分析依靠传统传感器融合的方法来估计设备方向基于神经网络的方法不依赖外部设备的方向信息回归速度大小和方向变化主要内容数据集规模个建筑个序列的运动数据轨迹和数据均为个人采集个安卓设备真实自然袋子内携带口袋中行走坐立徘徊等采集方式双设备采集跟踪设备连接在身体上采集设备可以自由活动受试者在前内直接行走将这个偏移角定为身体运动方向和运动方向的恒定偏移网络输入航向不可知的坐标系下的观测加速度和角速度输出当地导航坐标系下每帧的速度向量三个目的从给定的传感器历史数据的情况下回归速度向量两个关键设计定义输入和输出特征空间的坐标归一化即便是有噪声鲁棒速度损失提高了信噪比坐标系归一化传感器测量来自于本体坐标系地面真实的运动轨迹来自当地导航坐标系使用航向不可知的坐标系来表示输入和输出速度数据假设用本体坐标系编码数据本体坐标每帧数据变化导致运动不一致即使一个人完全相同的运动目标速度会根据人拿手机的方式不一致使用于航向无关的坐标系即轴与重力对齐的任何坐标在训练期间每一步使用随机的通过在水平面上随机旋转真实的轨迹来实现数据通过设备方向和相同的水平旋转转换为相同的网络结构采用的版本最后添加个单元的来回归向量在第帧处网络将帧到帧的输入数据的并在第帧处产生速度向量在测试时对每个帧进行预测整合以输出运动轨迹采用堆叠的单向通过连接双线性层的输出来丰富输入特征层每层个单元为每个帧回归速度向量添加额外的集成层来计算损失个残差块分别有个通道其中大小为的卷积核导致帧的感受野鲁棒速度损失潜在速度损失随时间回归一系列二维速度向量添加一个集成层该层对向量求和超过帧根据同一帧位置差异定义一个范数这种差异强制每帧向量总和必须匹配位置差异跨步速度损失学习预测帧步幅的位置差异而不是速度具体来说是计算第帧的网络输出与差异的损失其中是全局帧处的地面真实位置身体航向网络输入航向不可知的坐标系下的观测加速度和角速度输出当地导航坐标系下的每帧身体航向角的和与位置回归不同当主体静止航向回归任务本质是模糊的假设一个人坐在椅子上仍需要及时访问数据来估计身体的方向因此借助来完成能够保持长内存的任务使用没有集成层的架构让网络预测一个向量它们是每帧身体航向角的和对真实的航向角的和使用损失还添加一个归一化的损失以确保是正确的三角函数值实验设备对于每帧抽取一个包含帧的样本每个随机打乱对于将序列展开为每帧步是到的随机整数对于每过帧提取帧的样本是到的随机整数优化器个小时收敛消融实验评估在三个数据集上对五种方法进行评估表示这部分测试数据也在训练集中表示测试数据不包含在训练集中位置评估绝对轨迹误差估计轨迹和的均方根误差相对轨迹误差固定时间间隔分钟内的均方根误差航向评估和表示的均方误差航向的平均角度误差对于一些复杂的运动情况错误会变得更大最多度但通常小于度基本内容作者主页论文摘要应用背景从测量历史来估计绝对位置室内定位面临问题解决方案神经惯性定位具体实现使用神经惯导技术将输入转为一系列速度向量序列观测速度向量序列使用结构从速度向量序列找到设备的位置速度向量序列位置高度是挑战贡献个小时的惯性传感器数据和地面真实位置现有方法相关工作室内定位惯性导航主要内容惯性定位问题输入加速度角速度输出带有时间戳的位置估计指标距离阈值米内正确位置估计的比率角度阈值度内正确的速度方向的比率位置比率是主要指标方向比率衡量时间的一致性惯性重定位任务一种惯性重定位任务与惯性定位有所不同在重新定位任务中位置二维坐标以及可选的运动方向是已知的这个任务模拟了一种场景每隔几分钟利用获取一个全局位置之后为了节省能源使用惯性测量单元传感器在定位间隔期间进行重新定位惯性定位数据集组成两所大学建筑和一个办公空间小时的运动轨迹数据位置为二维坐标没有垂直位移采集神经惯性定位输入对加速度积分后的相对速度向量相对于本体坐标系输出位置分布概率图不是从测量来回归位置而是先将传感器数据转换为速度向量任务的核心是将速度向量转换为位置估计两个基于的分支速度分支上编码一系列速度向量时间卷积网络压缩时间维度增强感受野自由位置回归分支下编码一系列位置似然速度分支该分支使用速度的历史数据来估计位置序列包含三个模块使用时间卷积网络将速度序列长度压缩倍允许处理更长的运动历史使用感受野为的两层将长度为的维速度向量转换为长度为的维特征向量将压缩的特征向量作为经过位置编码的特征向量为维度是是经过压缩后的维特征向量和是位置编码频率参数的计算每个的输出也是维向量有块自注意力网络每块内有个标准的层和路多头注意力第一块生成的特征向量被传递给了另一个分支传入的维特征被重新排列为类似于图像的这图像特征体张量是场景绑定的需要根据不同的场景做出变换原文也说了在三个不同的场景这里分别是不同的通过具有转置卷积的层全卷积解码器进行上采样转置卷积可以放大特征图的空间分辨率从特征张量中恢复出更细粒度的空间信息卷积为的卷积该卷积层的参数不在像素之间共享不同位置的卷积核是独立的这一特性允许网络在每个位置上捕获局部的信息比如某些位置上可能无法出现目标或目标经常出现在特定区域生成概率分布图网络输出一个概率图表示时间步的位置信息概率图大小为概率值解释为在位置上目标出现的可能性自回归位置分支位置分支结合了速度分支和先验位置似然的速度特征这些特征来自于它过去的推理外部额外的位置信息比如使用卷积神经网络将每个的似然图转换为维的特征向量然后全部拆分使用相同的位置编码维度为将位置编码添加到特征向量中在每个自注意力层之后通过交叉注意力从速度分支注入速度特征合成数据生成需要大量数据在不同的时间窗口上裁剪数据当训练数据不够时采用下面三种方法生成计算训练轨迹的可能性图从高似然区域随机选择一对位置解决优化问题以产生平滑并通过高似然区域的轨迹实验交叉熵损失是真实轨迹的二值图像基本内容作者主页论文摘要应用背景面临问题解决方案具体实现贡献相关工作主要内容实验',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-11-16 21:05:33',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/img/avatar.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><div class="back-home-button"><i class="anzhiyufont anzhiyu-icon-grip-vertical"></i><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://index.anheyu.com/" title="个人主页"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2748ef34.jpg" alt="个人主页"/><span class="back-menu-item-text">个人主页</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div></div><a id="site-name" href="/" accesskey="h"><div class="title">11的Blog</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button only-home" id="travellings_button" title="随机前往一个开往项目网站"><a class="site-page" onclick="anzhiyu.totraveling()" title="随机前往一个开往项目网站" href="javascript:void(0);" rel="external nofollow" data-pjax-state="external"><i class="anzhiyufont anzhiyu-icon-train"></i></a></div><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="/img/wechatpay.jpg" target="_blank"><img class="post-qr-code-img" alt="微信" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/wechatpay.jpg"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" alt="支付宝" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/alipay.jpg"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/408/" style="font-size: 1.05rem;">408<sup>4</sup></a><a href="/tags/Anaconda/" style="font-size: 1.05rem;">Anaconda<sup>1</sup></a><a href="/tags/C/" style="font-size: 1.05rem;">C++<sup>1</sup></a><a href="/tags/CMake/" style="font-size: 1.05rem;">CMake<sup>1</sup></a><a href="/tags/Carla/" style="font-size: 1.05rem;">Carla<sup>1</sup></a><a href="/tags/Docker/" style="font-size: 1.05rem;">Docker<sup>1</sup></a><a href="/tags/GNSS/" style="font-size: 1.05rem;">GNSS<sup>1</sup></a><a href="/tags/Git/" style="font-size: 1.05rem;">Git<sup>1</sup></a><a href="/tags/Latex/" style="font-size: 1.05rem;">Latex<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>1</sup></a><a href="/tags/Pipe/" style="font-size: 1.05rem;">Pipe<sup>1</sup></a><a href="/tags/Python/" style="font-size: 1.05rem;">Python<sup>1</sup></a><a href="/tags/Ros/" style="font-size: 1.05rem;">Ros<sup>1</sup></a><a href="/tags/SCP/" style="font-size: 1.05rem;">SCP<sup>1</sup></a><a href="/tags/SSH/" style="font-size: 1.05rem;">SSH<sup>1</sup></a><a href="/tags/Tmux/" style="font-size: 1.05rem;">Tmux<sup>2</sup></a><a href="/tags/Vim/" style="font-size: 1.05rem;">Vim<sup>2</sup></a><a href="/tags/WSL/" style="font-size: 1.05rem;">WSL<sup>1</sup></a><a href="/tags/easyRL%E8%98%91%E8%8F%87%E4%B9%A6/" style="font-size: 1.05rem;">easyRL蘑菇书<sup>1</sup></a><a href="/tags/%E5%9B%BE%E5%BA%8A/" style="font-size: 1.05rem;">图床<sup>1</sup></a><a href="/tags/%E5%AE%9E%E7%94%A8%E6%95%99%E7%A8%8B/" style="font-size: 1.05rem;">实用教程<sup>4</sup></a><a href="/tags/%E5%AF%BC%E8%88%AA%E5%AE%9A%E4%BD%8D/" style="font-size: 1.05rem;">导航定位<sup>1</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 1.05rem;">工具<sup>1</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/" style="font-size: 1.05rem;">工具配置<sup>1</sup></a><a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 1.05rem;">强化学习<sup>1</sup></a><a href="/tags/%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA/" style="font-size: 1.05rem;">惯性导航<sup>1</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 1.05rem;">操作系统<sup>2</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 1.05rem;">数据结构<sup>1</sup></a><a href="/tags/%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%B7%A5%E5%85%B7/" style="font-size: 1.05rem;">文本编辑工具<sup>2</sup></a><a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/" style="font-size: 1.05rem;">服务器配置<sup>1</sup></a><a href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 1.05rem;">机器人操作系统<sup>1</sup></a><a href="/tags/%E6%9D%8E%E8%A7%85%E9%9D%92%E4%BA%BA%E5%83%8F/" style="font-size: 1.05rem;">李觅青人像<sup>1</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/" style="font-size: 1.05rem;">深度学习工具<sup>5</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 1.05rem;">算法<sup>1</sup></a><a href="/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" style="font-size: 1.05rem;">编程语言<sup>1</sup></a><a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/" style="font-size: 1.05rem;">自动驾驶<sup>4</sup></a><a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BB%BF%E7%9C%9F/" style="font-size: 1.05rem;">自动驾驶仿真<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" style="font-size: 1.05rem;">计算机组成原理<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 1.05rem;">计算机网络<sup>1</sup></a><a href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/" style="font-size: 1.05rem;">路径规划<sup>1</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span><a class="card-more-btn" href="/archives/" title="查看更多">
    <i class="anzhiyufont anzhiyu-icon-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/10/"><span class="card-archive-list-date">十月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">5</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/08/"><span class="card-archive-list-date">八月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/07/"><span class="card-archive-list-date">七月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">4</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/05/"><span class="card-archive-list-date">五月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/04/"><span class="card-archive-list-date">四月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/03/"><span class="card-archive-list-date">三月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">一月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div><div class="console-btn-item" id="consoleKeyboard" onclick="anzhiyu.keyboardToggle()" title="快捷键开关"><a class="keyboard-switch"><i class="anzhiyufont anzhiyu-icon-keyboard"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/" itemprop="url">论文</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>论文</span></a><a class="article-meta__tags" href="/tags/%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>组会汇报</span></a></span></div></div><h1 class="post-title" itemprop="name headline">PaperReading</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2024-10-20T03:58:03.000Z" title="发表于 2024-10-20 11:58:03">2024-10-20</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2024-11-16T13:05:33.952Z" title="更新于 2024-11-16 21:05:33">2024-11-16</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">9.4k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>34分钟</span></span><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="PaperReading"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为江苏/徐州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>江苏/徐州</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/"><header><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/" itemprop="url">论文</a><a href="/tags/%E8%AE%BA%E6%96%87/" tabindex="-1" itemprop="url">论文</a><a href="/tags/%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5/" tabindex="-1" itemprop="url">组会汇报</a><h1 id="CrawlerTitle" itemprop="name headline">PaperReading</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">11andyy</span><time itemprop="dateCreated datePublished" datetime="2024-10-20T03:58:03.000Z" title="发表于 2024-10-20 11:58:03">2024-10-20</time><time itemprop="dateCreated datePublished" datetime="2024-11-16T13:05:33.952Z" title="更新于 2024-11-16 21:05:33">2024-11-16</time></header><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026200925920.png" alt="image-20241026200925920"></p>
<h1 id="基于神经网络的惯性导航定位"><a href="#基于神经网络的惯性导航定位" class="headerlink" title="基于神经网络的惯性导航定位"></a>基于神经网络的惯性导航定位</h1><div class="table-container">
<table>
<thead>
<tr>
<th>论文</th>
<th>场景</th>
<th>网络</th>
<th>期刊/会议</th>
<th>代码</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="##IONet: Learning to Cure the Curse of Drift in Inertial Odometry">IONet: Learning to Cure the Curse of Drift in Inertial Odometry</a></td>
<td>Pedestrian</td>
<td>LSTM</td>
<td>2018 AAAI</td>
<td></td>
</tr>
<tr>
<td><a href="##RIDI: Robust IMU Double Integration">RIDI: Robust IMU Double Integration</a></td>
<td>Pedestrian</td>
<td>SVM、SVR</td>
<td>2018 ECCV</td>
<td><a target="_blank" rel="noopener" href="https://github.com/higerra/ridi_imu">code</a></td>
</tr>
<tr>
<td><a href="##RINS-W: Robust Inertial Navigation System on Wheels">RINS-W: Robust Inertial Navigation System on Wheels</a></td>
<td>Vehicle</td>
<td>RNN</td>
<td>2019 IROS</td>
<td><a target="_blank" rel="noopener" href="https://github.com/mbrossar/RINS-W">code</a></td>
</tr>
<tr>
<td><a href="##RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, and New Methods">RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, and New Methods</a></td>
<td>Pedestrian</td>
<td>ResNet、LSTM、TCN</td>
<td>2020 ICRA</td>
<td><a target="_blank" rel="noopener" href="https://github.com/Sachini/ronin">code</a></td>
</tr>
<tr>
<td><a href="##AI-IMU Dead-Reckoning">AI-IMU Dead-Reckoning</a></td>
<td>Vehicle</td>
<td>ConvNet</td>
<td>2020 IEEE Transactions on Intelligent Vehicles</td>
<td><a target="_blank" rel="noopener" href="https://github.com/mbrossar/ai-imu-dr">code</a></td>
</tr>
<tr>
<td><a href="##Neural Inertial Localization">Neural Inertial Localization</a></td>
<td>Pedestrian</td>
<td>TCN、Transformer</td>
<td>2022 CVPR</td>
<td><a target="_blank" rel="noopener" href="https://github.com/Sachini/niloc">code</a></td>
</tr>
<tr>
<td>IDOL: Inertial Deep Orientation-Estimation and Localization</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>TLIO: Tight Learned Inertial Odometry</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Deep Learning Based Speed Estimation for Constraining Strapdown Inertial Navigation on Smartphones</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h2 id="IONet-Learning-to-Cure-the-Curse-of-Drift-in-Inertial-Odometry"><a href="#IONet-Learning-to-Cure-the-Curse-of-Drift-in-Inertial-Odometry" class="headerlink" title="IONet: Learning to Cure the Curse of Drift in Inertial Odometry"></a>IONet: Learning to Cure the Curse of Drift in Inertial Odometry</h2><h3 id="基本内容"><a href="#基本内容" class="headerlink" title="基本内容"></a>基本内容</h3><ol>
<li><p><strong>作者</strong>：<strong>Changhao Chen</strong>, Xiaoxuan Lu, Andrew Markham, Niki Trigoni <strong>Department of Computer Science, University of Oxford</strong>, United Kingdom</p>
</li>
<li><p><strong>主页</strong>：<a target="_blank" rel="noopener" href="https://changhao-chen.github.io/">https://changhao-chen.github.io/</a></p>
</li>
<li><p><strong>Github</strong>：未开源</p>
</li>
<li><strong>论文（2018 AAAI）：</strong><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4544422971728093185&amp;noteId=2539111411423227136">https://readpaper.com/pdf-annotate/note?pdfId=4544422971728093185&amp;noteId=2539111411423227136</a></li>
</ol>
<h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>应用背景：惯性传感器的室内定位</li>
<li>面临问题：惯性传感器的加速度输出，当<strong>对加速度二重积分后得到位移</strong>误差会增大</li>
<li>解决方案：不采用二重积分，将惯性数据切分成一个个窗口，估计每一个窗口内，物体的速度和方向</li>
<li>具体实现：通过<strong>深度递归神经网络</strong>输入<strong>原始的IMU序列数据</strong>，输出得到<strong>完整的高精度轨迹</strong></li>
<li>贡献<ol>
<li>通过牛顿力学推导出<strong>基于序列的物理模型</strong>，将<strong>惯性跟踪问题转为顺序学习问题</strong></li>
<li><strong>首个</strong>深度神经网络，从原始的IMU输出数据，学习<strong>极坐标的位置变换</strong></li>
<li>论证了模型还可以推广到<strong>一般的非周期性的运动</strong>，比如婴儿车（时走时停）</li>
</ol>
</li>
</ol>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><ol>
<li><p>捷联惯性导航系统（Strapdown Inertial Navigation System）</p>
</li>
<li><p>行人航位推算（Pedestrian Dead Reckoning）</p>
<p>PDR 使用惯性测量来检测步骤，通过经验公式估计步幅长度和航向，但是<strong>动态步长</strong>估计受到传感器噪声的影响，还需要根据用户的运动习惯仔细调整大量参数</p>
</li>
<li><p>序列的深度学习（Sequential Deep Learning）</p>
<p>视觉里程计，本文提出首个<strong>仅使用惯性数据实现的惯性里程计</strong></p>
</li>
</ol>
<h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><h4 id="惯性跟踪"><a href="#惯性跟踪" class="headerlink" title="惯性跟踪"></a>惯性跟踪</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/198fd5f50c1825a183f423ca610301b7_1_Figure_2.png" alt="198fd5f50c1825a183f423ca610301b7_1_Figure_2"></p>
<ol>
<li><p>姿态更新（Attitude Update）</p>
<ol>
<li><p><strong>角速度测量</strong>：从$t-1$到$t$时刻，利用IMU测量得到物体的角速度$\omega(t)$，即三个轴上的角速度</p>
</li>
<li><p><strong>旋转角度计算</strong>：角速度$\omega(t)$与时间微元$d(t)$相乘，得到<strong>微小的角度旋转量</strong></p>
<script type="math/tex; mode=display">
\sigma = \omega × d(t)</script></li>
<li><p><strong>构建相对旋转矩阵</strong>：利用$\sigma$生成相对旋转矩阵$\Omega(t)$（表示物体从$t-1$时刻到$t$时刻的相对变换）</p>
<script type="math/tex; mode=display">
\Omega(t)=\mathbf{C}_{b_{t}}^{b_{t-1}}=I+\frac{sin(\sigma)}{\sigma}[\sigma\times]+\frac{1-cos(\sigma)}{\sigma^{2}}[\sigma\times]^{2}</script><p>该公式源自 Rodrigues 旋转公式，相对旋转矩阵$\Omega(t)=C_{b_{t-1}}^{b_t}$<strong>表示载体坐标系（就是IMU的坐标）</strong>从$t-1$时刻到$t$时刻的变换</p>
<p>其中$[\sigma\times]$表示角度$\sigma$的叉积矩阵，如果$\sigma = (\sigma_x, \sigma_y, \sigma_z)$，叉积矩阵可以表示为：</p>
<script type="math/tex; mode=display">
[\sigma\times]=\begin{bmatrix}0&-\sigma_z&\sigma_y\\\sigma_z&0&-\sigma_x\\-\sigma_y&\sigma_x&0\end{bmatrix}</script><p>这里的$sin(\sigma),cos(\sigma),\sigma$都是标量计算</p>
<script type="math/tex; mode=display">
\sigma=\|\vec{\sigma}\|=\sqrt{\sigma_x^2+\sigma_y^2+\sigma_z^2}\\
\Omega(t)=I+\frac{\sin(\|\vec{\sigma}\|)}{\|\vec{\sigma}\|}[\vec{\sigma}\times]+\frac{1-\cos(\|\vec{\sigma}\|)}{\|\vec{\sigma}\|^2}[\vec{\sigma}\times]^2</script><p>第一项：单位矩阵</p>
<p>第二项：线性项，表示旋转的初始变化</p>
<p>第三项：非线性项，描述旋转角度增加时的高阶影响</p>
<p><strong>当旋转角度很小时，$sin(\sigma)≈\sigma,cos(\sigma)≈1- \frac{\sigma ^2}{2}$</strong>，可以简化为更简单的线性关系</p>
</li>
<li><p><strong>更新方向余弦矩阵</strong>：将上一刻的方向余弦矩阵$C_b^n(t-1)$和相对旋转矩阵$\Omega(t)$相乘，得到当前的方向余弦矩阵</p>
<script type="math/tex; mode=display">
C_b^n(t)=C_b^n(t-1)\cdot\Omega(t)</script><p><strong>我的理解：$t$时刻，载体系到导航坐标系的变换=$t-1$时刻载体系到导航坐标系的变换 * 从$t-1$时刻到$t$时刻载体系的变换</strong></p>
<p>该更新公式表示物体姿态的累积变化，使导航系统能够跟踪物体在三维空间中的连续姿态变化</p>
</li>
</ol>
</li>
<li><p>速度更新（Velocity Update)</p>
<p>对速度的更新，实际上就是计算比力，然后对比力进行积分，这里都是向量形式。</p>
<script type="math/tex; mode=display">
\mathrm{v}(t)=\mathrm{v}(t-1)+((\mathrm{C}_b^n(t-1))*\mathrm{a}(t)-\mathrm{g}_n)dt</script><ol>
<li><p><strong>获取加速度的测量值：</strong>从IMU获取载体坐标系下的加速度$\mathrm{a}(t)$</p>
</li>
<li><p><strong>计算导航坐标系下的比力：</strong>将加速度$\mathrm{a}(t)$从载体坐标系转换到导航坐标系==为什么用t-1==</p>
<script type="math/tex; mode=display">
C_b^n(t-1)\cdot a(t)-\mathrm{g}_n</script></li>
<li><p><strong>积分更新速度</strong></p>
</li>
</ol>
</li>
<li><p>位置更新（Location Update）</p>
<p>对位置的更新，实际上就是对速度积分</p>
<script type="math/tex; mode=display">
\mathbf{L}(t)=\mathbf{L}(t-1)+\mathbf{v}(t-1)dt</script></li>
</ol>
<p><strong>面临两大问题：</strong></p>
<ol>
<li>噪声</li>
<li>初始化时间久，不适用行人轨迹跟踪任务</li>
</ol>
<h4 id="按窗口切分惯性数据"><a href="#按窗口切分惯性数据" class="headerlink" title="按窗口切分惯性数据"></a>按窗口切分惯性数据</h4><p>按照窗口切分惯性数据，估计每个窗口的姿态、速度、位置是不合理的，因为每个窗口的数据并不是独立的，当前的状态需要从上一个状态推导得到。</p>
<p>因此目标是：伪独立性，估计每个窗口的导航状态变化。<strong>遵循这一思想，我们从运动的基本牛顿定律推导出一种新的基于序列的物理模型，并将其重新表述为学习模型。</strong></p>
<h5 id="位移"><a href="#位移" class="headerlink" title="位移"></a>位移</h5><p>传统的惯导系统，可以用下述公式来表述：</p>
<script type="math/tex; mode=display">
[\mathbf{C}_b^n\quad\mathbf{v}\quad\mathbf{L}]_t=f([\mathbf{C}_b^n\quad\mathbf{v}\quad\mathbf{L}]_{t-1},[\mathbf{a}\quad\mathbf{w}]_t)</script><ol>
<li><p>计算位移在$n$个窗口内的变化</p>
<script type="math/tex; mode=display">
\Delta\mathbf{L}=\int_{t=0}^{n-1}\mathbf{v}(t)dt</script></li>
<li><p>将这个总位移看成两部分的和相加</p>
<script type="math/tex; mode=display">
\Delta L=n\cdot v(0)\cdot dt+[(n-1)s_1+(n-2)s_2+\cdots+s_{n-1}]\cdot dt^2</script></li>
</ol>
<ol>
<li>一部分是初始速度的在$n×dt$时间内的累积贡献$n\cdot v(0)\cdot dt$</li>
<li>另一部分是每一段的加速度对时间的累积贡献$s(t)=C_b^n(t-1)\cdot a(t)-g$</li>
<li><strong>这个公式特别像$x=v_0t+\frac {1}{2} at^2$</strong></li>
</ol>
<ol>
<li><p>上述总位移公式可以进一步推导为（需要结合前面的姿态更新的计算）</p>
<script type="math/tex; mode=display">
\Delta\mathbf{L}=n\mathbf{v}(0)dt+[(n-1)\mathbf{C}_b^n(0)*\mathbf{a}_1+(n-2)\mathbf{C}_b^n(0)\boldsymbol{\Omega}(1)\\*\mathbf{a}_2+\cdots+\mathbf{C}_b^n(0)\prod^{n-2}\Omega(i)*\mathbf{a}_{n-1}]dt^2-\frac{n(n-1)}2\mathbf{g}dt^2</script></li>
<li><p>进一步简化为：</p>
<script type="math/tex; mode=display">
\Delta\mathbf{L}=n\mathbf{v}(0)dt+\mathbf{C}_b^n(0)\mathbf{T}dt^2-\frac{n(n-1)}2\mathbf{g}dt^2 \\
\mathbf{T}=(n-1)\mathbf{a}_1+(n-2)\Omega(1)\mathbf{a}_2+\cdots+\prod_{i=1}^{n-2}\Omega(i)\mathbf{a}_{n-1}</script></li>
<li><p>因为考虑的室内定位问题，<strong>认为导航坐标系中$z$是没有变化的</strong>，因此计算位移的二范数</p>
<script type="math/tex; mode=display">
\begin{gathered}
\Delta l=\|n\mathbf{v}(0)dt+\mathbf{C}_b^n(0)\mathbf{T}dt^2-\frac{n(n-1)}2\mathbf{g}dt^2\|_2 \\
=\|\mathbf{C}_b^n(0)(n\mathbf{v}^b(0)dt+\mathbf{T}dt^2-\frac{n(n-1)}2\mathbf{g}_0^bdt^2)\|_2 
\end{gathered}</script><p><strong>注意这里的速度测得的是相对于载体坐标系的速度$v^b(0)$，重力加速度也是相对于载体坐标系的$g_0^b$，然后借助方向余弦矩阵转换到导航坐标系中</strong></p>
</li>
<li><p>由于方向余弦矩阵为正交矩阵，有：</p>
<script type="math/tex; mode=display">
\mathrm{C}_b^n(0)^T\mathrm{C}_b^n(0)=\mathbf{I}</script></li>
<li><p>在计算位移的二范数时，可以消掉，<strong>因此，哪怕我们不知道初始的位姿，我们也能计算得到位移</strong></p>
<script type="math/tex; mode=display">
\Delta l=\|\Delta\mathbf{L}\|_2=\|n\mathbf{v}^b(0)dt+\mathbf{T}dt^2-\frac{n(n-1)}2\mathbf{g}_0^bdt^2\|_2</script></li>
<li><p>因此，在窗口内，<strong>行进的水平距离可以表示为初始速度、重力和线加速度和角加速度的函数，所有这些都在载体坐标系的框架中</strong>：</p>
<script type="math/tex; mode=display">
\Delta l =f(v^b(0),g_0^b,a_{1:n},\omega_{1:n})</script></li>
</ol>
<h5 id="偏航角"><a href="#偏航角" class="headerlink" title="偏航角"></a>偏航角</h5><p>如何通过惯性测量单元（IMU）获取的原始数据来确定用户在水平面上的航向角$\Delta \psi$，并最终将传统模型转换为基于极坐标表示的模型$(\Delta l,\Delta \psi)$</p>
<ol>
<li><p>载体真实的加速度和角速度$(a_{1:n},\omega_{1:n})$是IMU的测量数据 的$({\hat{a}}_{1:n},{\hat{w}}_{1:n})$“隐含变量”，<strong>IMU的原始数据包含了一些噪声和偏差，而真正的加速度和角速度是隐含在这些测量数据中的，需要进一步处理才能得到真实值</strong></p>
</li>
<li><p>由于系统是在水平面上运动，因此姿态角（翻滚、俯仰、偏航）只有偏航角是关键的参数，<strong>换句话说，系统只关注用户在水平面上的旋转角度</strong></p>
</li>
<li><p>根据公式$\sigma = \omega × d(t)$和$\Omega(t)={\bf C}_{b_{t}}^{b_{t-1}}=I+\frac{sin(\sigma)}{\sigma}\left[\sigma\times\right]+\frac{1-cos(\sigma)}{\sigma^{2}}\left[\sigma\times\right]^{2}$可以将偏航角$\Delta \psi$表示为IMU测量数据的函数(<strong>提取$\Omega(t)$积分后的第三个分量</strong>)，利用原始数据来估计航向变化</p>
<script type="math/tex; mode=display">
(\Delta l ,\Delta \psi) =f_\theta(v^b(0),g_0^b,\hat a_{1:n},\hat \omega_{1:n})</script></li>
<li><p>起始位置和终止位置的关系可以写为，其中$x_0,y_0$是初始位置，$\psi_0$是初始偏航角</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{l l}{x_{n}=x_{0}+\Delta l c o s(\psi_{0}+\Delta\psi)}\\ {y_{n}=y_{0}+\Delta l s i n(\psi_{0}+\Delta\psi)}\end{array}\right.</script></li>
<li><p><strong>问题变为了如何通过将每个窗口转换为序列学习问题来隐式估计载体帧中的这种初始速度和重力</strong></p>
</li>
</ol>
<h4 id="深度学习网络框架"><a href="#深度学习网络框架" class="headerlink" title="深度学习网络框架"></a>深度学习网络框架</h4><ol>
<li>输入：每个窗口连续的IMU数据（本体坐标系下的加速度和角速度）</li>
<li>输出：每个窗口估计的导航坐标系下物体的位移和偏转角$\Delta l,\Delta\psi$</li>
</ol>
<p>将此公式$(\Delta l,\Delta\psi)=f_{\theta}(v^{b}(0),g_{0}^{b},\hat{a}_{1:n},\hat{\omega}_{1:n})$作为一个序列，输入是传感器观测到的数据，输出是极坐标向量；</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241030222648168.png" alt="image-20241030222648168"></p>
<script type="math/tex; mode=display">
({\bf a},{\bf w})_{200\ast6}\stackrel{f_{\theta}}{\longrightarrow}(\Delta l,\Delta\psi)_{1\ast2},</script><p>输入数据：每个窗口连续的IMU数据（IMU测量被分成步长为10帧(0.1s)的独立窗口）</p>
<p>输出数据：极坐标向量</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241030225637434.png" alt="image-20241030225637434"></p>
<p>网络：LSTM（两层：第一层的输出序列提供了第二层的输入序列。第二个 LSTM 输出一个极坐标向量来表示处理后的序列中的变换关系）</p>
<p>最优参数$\theta^*$可以通过最小化训练集$D=(X,Y)$上的损失函数来恢复</p>
<script type="math/tex; mode=display">
\begin{array}{l}\theta^{*}=\arg\operatorname*{min}_{\theta}\ell(f_{\theta}(\mathbf{X}),\mathbf{Y})\end{array}</script><p>损失函数：gt的$(\Delta\tilde{l},\Delta\tilde{\psi})$和估计值$(\Delta l,\Delta\psi)$的欧氏距离</p>
<script type="math/tex; mode=display">
\ell=\sum\|\Delta\tilde{l}-\Delta l\|_{2}^{2}+\kappa\|\Delta\tilde{\psi}-\Delta\psi\|_{2}^{2}</script><p>$\kappa$是调节权重（位移和偏航角哪个影响更大）的因子</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p><strong>没有公共数据集用于使用基于手机的IMU进行室内定位</strong></p>
<p>训练数据集由来自不同附件的手机的 IMU 数据组成，例如手持，在口袋里，手袋里，每个拖车 2 小时，由 iPhone 7Plus 收集</p>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>TensorFlow框架+TITAN X GPU+Adam优化器+100个epoch后收敛+每个LSTM层Dropout</p>
<p><strong>不同用户</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241030225650491.png" alt="image-20241030225650491"></p>
<p><strong>不同设备</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241030225700494.png" alt="image-20241030225700494"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241030225902616.png" alt="image-20241030225902616"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241030225800791.png" alt="image-20241030225800791"></p>
<h2 id="RIDI-Robust-IMU-Double-Integration"><a href="#RIDI-Robust-IMU-Double-Integration" class="headerlink" title="RIDI: Robust IMU Double Integration"></a>RIDI: Robust IMU Double Integration</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116183800297.png" alt="image-20241116183800297"></p>
<h3 id="基本内容-1"><a href="#基本内容-1" class="headerlink" title="基本内容"></a>基本内容</h3><ol>
<li><strong>作者：</strong>Hang Yan，Qi Shan，Yasutaka Furukawa</li>
<li><strong>主页：</strong><a target="_blank" rel="noopener" href="https://yanhangpublic.github.io/ridi/index.html">https://yanhangpublic.github.io/ridi/index.html</a></li>
<li><strong>Github：</strong><a target="_blank" rel="noopener" href="https://github.com/higerra/ridi_imu">https://github.com/higerra/ridi_imu</a></li>
<li><strong>论文（2018ECCV）：</strong><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4557950887721443329&amp;noteId=2582564980465618944">https://readpaper.com/pdf-annotate/note?pdfId=4557950887721443329&amp;noteId=2582564980465618944</a></li>
</ol>
<h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>应用背景：仅从每个智能手机中的惯性测量单元(IMU)估计人体运动的轨迹。</li>
<li>面临问题：IMU对速度双积分导致误差爆炸，手机的旋转和人的步行方向并不是完全重合的</li>
<li>解决方案：</li>
<li><p>具体实现：RIDI从IMU历史观测的<strong>加速度和角速度</strong>回归<strong>速度向量</strong>，纠正加速度中的低频误差以与回归的速度兼容，<strong>再使用标准的双积分从校正后的加速度来估计轨迹</strong></p>
<ol>
<li>输入：相对于S坐标系的IMU的<strong>加速度和角速度</strong>序列</li>
<li>输出：相对于S坐标系的<strong>二维速度向量</strong></li>
</ol>
</li>
<li><p>贡献</p>
<ol>
<li>和纯视觉惯性导航效果相当</li>
<li>数据驱动的惯性导航的第一篇工作</li>
<li>RIDI 产生与地面实况相当的运动轨迹，平均位置误差低于 3%</li>
</ol>
</li>
</ol>
<h3 id="相关工作-1"><a href="#相关工作-1" class="headerlink" title="相关工作"></a>相关工作</h3><ol>
<li>视觉SLAM（V-SLAM）</li>
<li>基于IMU的旋转估计很成功，被用于VR设备</li>
<li>基于WIFI的位置跟踪</li>
</ol>
<h3 id="主要内容-1"><a href="#主要内容-1" class="headerlink" title="主要内容"></a>主要内容</h3><p>前提：地板平坦，<strong>回归和位置估计是在二维平面上运行的</strong></p>
<p>鲁棒IMU双积分分为三步：</p>
<ol>
<li>RIDI从角速度和加速度回归速度向量</li>
<li>RIDI估计加速度的<strong>低频修正</strong>，使其<strong>积分的速度</strong>与<strong>回归的速度值</strong>相匹配</li>
<li>对校正后的加速度进行双积分以估计位置</li>
</ol>
<h4 id="坐标系"><a href="#坐标系" class="headerlink" title="坐标系"></a>坐标系</h4><p>在该算法中考虑三个坐标系：</p>
<ol>
<li><p>世界坐标系$W$，在世界坐标系中估计输出位置，$W$被设置为第一帧Android API的全局坐标系</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116190742872.png" alt="image-20241116190742872"></p>
</li>
<li><p>IMU设备坐标系$I$</p>
</li>
<li><p>和重力方向平行的一个坐标系S（图中绿色）：==这个坐标系使得回归任务变得简单，因为回归于设备的倾斜和滚动无关==</p>
</li>
</ol>
<h4 id="学习回归速度"><a href="#学习回归速度" class="headerlink" title="学习回归速度"></a>学习回归速度</h4><p><strong>在S坐标系中学习回归速度</strong></p>
<ol>
<li>对于每个训练的序列，我们先将设备的姿态（相对于W）以及设备的加速度和角速度（相对于I）都转换到相对于S坐标系</li>
<li>为了抑制高频噪声，使用$\sigma=2.0$的高斯平滑应用于六个输出量，使用$\sigma=30$应用于回归的两个速度分量上（x方向，y方向）</li>
<li>将历时200帧（1s）的角速度和线性加速度连接起来，构造1200维特征向量</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116192419250.png" alt="image-20241116192419250"></p>
<ol>
<li><p>人们会用不同的方式携带手机，在口袋、包里、手持、在身上，充分利用这些知识构造了一个<strong>级联的回归模型</strong>：先通过SVM进行分类，然后通过两个单独的SVR对速度的两个分量进行回归（<strong>速度只有水平方向的速度</strong>）</p>
</li>
<li><p>SVM和SVR超参数</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116193202449.png" alt="image-20241116193202449"></p>
</li>
</ol>
<h4 id="修正加速度误差"><a href="#修正加速度误差" class="headerlink" title="修正加速度误差"></a>修正加速度误差</h4><p>==预测速度在去除传感器噪声和偏差方面提供了有效的线索==</p>
<ol>
<li><p>我们做了一个简化的假设，将所有的误差建模为<strong>线性加速度的低频误差</strong>，绕过了显示的误差建模，转而将问题转化为<strong>简单的最小二乘问题</strong></p>
</li>
<li><p>对IMU坐标系的加速度偏差进行建模，<strong>将偏差表示为，在采样帧${\mathcal{F}}_{1}$处，校正项$x_I^f$的线性插值</strong></p>
</li>
<li><p>为了对这种低频偏差进行建模，<strong>作者假设偏差在采样帧上是线性变化的。每隔50帧设置一个偏差修正项$x_I^f$</strong>，减少计算量</p>
</li>
<li><p>例如：$x_I^{11}$是第11帧的加速度偏差，它的值是通过第1帧和第51帧的偏差修正项计算出来的$x_I^{11}=0.8x_I^1+0.2x_I^{51}$，权重0.8和0.2是根据第11帧在第1帧和第51</p>
<p>帧之间的位置比例计算出来的</p>
</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116200710319.png" alt="image-20241116200710319"></p>
<p>目标是<strong>最小化子采样帧${\mathcal{F}}_{2}$集合内两个速度之间的差异来优化子采样帧${\mathcal{F}}_{1}$集合内的各个${x_I^f}$</strong>，而不是对每一帧都这样处理</p>
<p>下面两个速度是相对于S坐标系来定义的：</p>
<ol>
<li>修正后的速度$v_C^f$，通过修正线性加速度，积分后得到的速度</li>
<li>回归速度$v_R^f$，通过SVR回归得到的速度</li>
</ol>
<p>该优化问题：</p>
<script type="math/tex; mode=display">
\operatorname*{min}_{\{x_{I}^{1},x_{I}^{51},\cdots\}}\sum_{f\in{\mathcal{F}}_{2}}\left\|v_{C}^{f}-v_{R}^{f}\right\|^{2}+\lambda\sum_{f\in{\mathcal{F}}_{1}}\left\|x_{I}^{f}\right\|^{2}</script><ol>
<li>第一项：$\sum_{f\in{\mathcal{F}}_{2}}\left|v_{C}^{f}-v_{R}^{f}\right|^{2}$,最小化这两个速度差异，确保回归值更接近速度的真实值</li>
<li>第二项：$\lambda\sum_{f\in{\mathcal{F}}_{1}}\left|x_{I}^{f}\right|^{2}$,正则化项，约束修正项不要变化过于剧烈</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116203525108.png" alt="image-20241116203525108"></p>
<p>修正的速度$v_c^f$计算：</p>
<script type="math/tex; mode=display">
v_{C}^{f}={\mathcal R}_{S W}^{f}\sum_{f^{\prime}=1}^{f}{\mathcal R}_{W I}^{f^{\prime}}\left(a_{I}^{f^{\prime}}+x_{I}^{f^{\prime}}\right)</script><ol>
<li>先对加速度进行修正：相对于I坐标系的每一帧的加速度加上修正的偏差$\left(a_{I}^{f^{\prime}}+x_{I}^{f^{\prime}}\right)$</li>
<li>将IMU坐标系下的加速度转到世界坐标系下的加速度然后进行积分得到速度</li>
<li>再将这个速度转移到稳定的IMU坐标系：S坐标系下</li>
</ol>
<h3 id="实验-1"><a href="#实验-1" class="headerlink" title="实验"></a>实验</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241116203103533.png" alt="image-20241116203103533"></p>
<h2 id="RINS-W-Robust-Inertial-Navigation-System-on-Wheels"><a href="#RINS-W-Robust-Inertial-Navigation-System-on-Wheels" class="headerlink" title="RINS-W: Robust Inertial Navigation System on Wheels"></a>RINS-W: Robust Inertial Navigation System on Wheels</h2><h3 id="基本内容-2"><a href="#基本内容-2" class="headerlink" title="基本内容"></a>基本内容</h3><ol>
<li><strong>作者：</strong>Martin Brossard, Axel Barrau, Silvere Bonnabel <strong>MINES ParisTech, PSL Research University, Centre for Robotics</strong></li>
<li><strong>主页：</strong></li>
<li><strong>Github：</strong><a target="_blank" rel="noopener" href="https://github.com/mbrossar/RINS-W">https://github.com/mbrossar/RINS-W</a></li>
<li><strong>论文(2019 IROS)：</strong><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=2565365605201437440&amp;noteId=2565365766144784128">https://readpaper.com/pdf-annotate/note?pdfId=2565365605201437440&amp;noteId=2565365766144784128</a></li>
</ol>
<h3 id="摘要-2"><a href="#摘要-2" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>应用背景：使用IMU进行长期惯性导航的实时方法，用于<strong>轮式机器人</strong></li>
<li>面临问题：</li>
<li>解决方案：</li>
<li>具体实现：<ol>
<li>一种鲁棒检测器：使用循环神经网络动态检测各种感兴趣的情况（比如零速度or横向偏移）</li>
<li>一种最先进的卡尔曼滤波器：将知识作为定位的伪测量</li>
</ol>
</li>
<li>贡献<ol>
<li>在公开数据集上可以实现21km长距离轨迹大于20m的最终精度</li>
<li>第一篇将深度学习技术和滤波方法结合的论文，用于轮式车辆纯惯性导航</li>
<li>该方法不仅限于基于IMU的导航。可以将卡尔曼滤波器与其他传感器的测量输入</li>
</ol>
</li>
</ol>
<h3 id="相关工作-2"><a href="#相关工作-2" class="headerlink" title="相关工作"></a>相关工作</h3><ol>
<li>使用惯性传感器和视觉-惯性系统的里程计与定位</li>
<li>车辆约束的使用以提高定位的鲁棒性</li>
<li>零速度更新（ZUPT）</li>
<li>自适应卡尔曼滤波</li>
</ol>
<h3 id="主要内容-2"><a href="#主要内容-2" class="headerlink" title="主要内容"></a>主要内容</h3><h4 id="惯性导航系统和传感器模型"><a href="#惯性导航系统和传感器模型" class="headerlink" title="惯性导航系统和传感器模型"></a>惯性导航系统和传感器模型</h4><h5 id="惯性导航系统"><a href="#惯性导航系统" class="headerlink" title="惯性导航系统"></a>惯性导航系统</h5><p>假定IMU的方向 $\mathbf{R}_{n}\;\in\;S O(3)$，旋转矩阵是将坐标从载体坐标系映射到世界坐标系$w$，$v_n^{w}$表示第n帧在世界坐标系下的速度，$p_n^w$表示第n帧在世界坐标系下的位置，惯性导航系统模型可以写为：</p>
<script type="math/tex; mode=display">
\begin{array}{l}{\mathbf{R}_{n+1}=\mathbf{R}_{n}\exp_{S O(3)}\left(\omega_{n}d t\right)}\\ {\mathbf{v}_{n+1}^{\mathrm{w}}=\mathbf{v}_{n}^{\mathrm{w}}+\left(\mathbf{R}_{n}\mathbf{a}_{n}+\mathbf{g}\right)d t}\\ {\mathbf{p}_{n+1}^{\mathrm{w}}=\mathbf{p}_{n}^{\mathrm{w}}+\mathbf{v}_{n}^{\mathrm{w}}d t}\end{array}</script><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105163703880.png" alt="image-20241105163703880"></p>
<p>$(R_0,v_0^w,p_0^w)$为初始值，在应用场景中，忽略地球自转和科里奥利力，即认为地球是平坦的</p>
<h5 id="IMU模型"><a href="#IMU模型" class="headerlink" title="IMU模型"></a>IMU模型</h5><p>对于IMU的建模，<strong>IMU的测量值=真实值+偏置+噪声</strong></p>
<script type="math/tex; mode=display">
\begin{array}{l}\omega_{n}^{\mathrm{IMU}}=\omega_{n}+\mathbf{b}_{n}^{\omega}+\mathbf{w}_{n}^{\omega},\\\mathbf{a}_{n}^{\mathrm{IMU}}=\mathbf{a}_{n}+\mathbf{b}_{n}^{\mathbf{a}}+\mathbf{w}_{n}^{\mathbf{a}},\end{array}</script><p>$b_n^{\omega},b_n^{\mathbf{a}}$为零偏，$w_n^{\omega},w_n^{\mathbf{a}}$为0均值高斯噪声，偏置遵循随机游动（random-walk）,下一帧的偏置等于上一帧的偏置+噪声</p>
<script type="math/tex; mode=display">
\mathbf{b}_{n+1}^{\omega}=\mathbf{b}_{n}^{\omega}+\mathbf{w}_{n}^{\mathbf{b}_{\omega}}\, \\
\mathbf{b_{n+1}^{\mathbf{a}}}=\mathbf{b_{n}^{\mathbf{a}}}+\mathbf{w_{n}^{\mathbf{b_{a}}}}</script><h4 id="轮式机器人运动特性"><a href="#轮式机器人运动特性" class="headerlink" title="轮式机器人运动特性"></a>轮式机器人运动特性</h4><h5 id="轮式机器人运动轮廓"><a href="#轮式机器人运动轮廓" class="headerlink" title="轮式机器人运动轮廓"></a>轮式机器人运动轮廓</h5><p>考虑四种不同的运动状态，其有效性用01来进行编码：</p>
<script type="math/tex; mode=display">
{\bf z}_{n}=\left(z_{n}^{\mathrm{VEL}},\ z_{n}^{\mathrm{ANG}},\ z_{n}^{\mathrm{LAT}},\ z_{n}^{\mathrm{UP}}\right)\in\{0,1\}^{4}</script><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105165003952.png" alt="image-20241105165003952"></p>
<ol>
<li><p>零速度状态</p>
<p>零速度状态满足两个约束，即速度为0，比力为0</p>
<script type="math/tex; mode=display">
z_{n}^{\mathrm{VEL}}=1\Rightarrow\left\{\begin{array}{l l}{\mathbf{v}_{n}=\mathbf{0}}\\ {\mathbf{R}_{n}\mathbf{a}_{n}+\mathbf{g}=\mathbf{0}}\end{array}\right.</script></li>
<li><p>零角速度状态</p>
<script type="math/tex; mode=display">
z_{n}^{\mathrm{ANG}}=1\Rightarrow\omega_{n}=0</script></li>
<li><p>零侧向速度</p>
<script type="math/tex; mode=display">
z_{n}^{\mathrm{LAT}}=1\Rightarrow v_{n}^{\mathrm{LAT}}\simeq0</script><p>可以对速度进行分解：前向、横向、垂向速度：</p>
<script type="math/tex; mode=display">
\mathbf{v}_{n}^{\mathsf{B}}=\mathbf{R}_{n}^{T}\mathbf{v}_{n}^{\mathsf{w}}={\begin{bmatrix}v_{n}^{\mathsf{FOR}}\\ v_{n}^{\mathsf{LAT}}\\ v_{n}^{\mathsf{UP}}\end{bmatrix}}</script></li>
<li><p>零垂直速度</p>
<script type="math/tex; mode=display">
z_{n}^{\mathrm{up}}=1\Rightarrow v_{n}^{\mathrm{up}}\simeq0</script><p><strong>零侧向速度和零垂直速度是轮式机器人在常见道路形式的一般性假设</strong></p>
</li>
</ol>
<h5 id="轮式机器人运动轮廓的选择"><a href="#轮式机器人运动轮廓的选择" class="headerlink" title="轮式机器人运动轮廓的选择"></a>轮式机器人运动轮廓的选择</h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105165759490.png" alt="image-20241105165759490"></p>
<h4 id="RINS-W算法"><a href="#RINS-W算法" class="headerlink" title="RINS-W算法"></a>RINS-W算法</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108143327572.png" alt="image-20241108143327572"></p>
<p><strong>从IMU中恢复轨迹和传感器偏差估计</strong>：</p>
<ol>
<li>检测器是递归神经网络：从原始IMU信号估计<strong>二进制向量</strong>$z_n$，判断是哪一个速度状态（从原始IMU信号识别特定运动轮廓）</li>
<li>滤波器在动力学模型集成IMU测量值，利用检测到的运动轮廓作为伪测量来细化估计</li>
</ol>
<p>检测器不使用滤波器的输出，而是独立使用原始IMU信号进行训练</p>
<h5 id="特定的运动轮廓检测器（LSTM）"><a href="#特定的运动轮廓检测器（LSTM）" class="headerlink" title="特定的运动轮廓检测器（LSTM）"></a>特定的运动轮廓检测器（LSTM）</h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108145002536.png" alt="image-20241108145002536"></p>
<p>检测器在每个时刻$n$，检测物体处于哪一个运动状态${\bf z}_{n}=\left(z_{n}^{\mathrm{VEL}},\ z_{n}^{\mathrm{ANG}},\ z_{n}^{\mathrm{LAT}},\ z_{n}^{\mathrm{UP}}\right)\in\{0,1\}^{4}$,所用LSTM</p>
<script type="math/tex; mode=display">
\hat{\mathbf{u}}_{n+1},\ \mathbf{h}_{n+1}=LSTM(\{ \omega^{IMU}_i,a^{IMU}_i\}_{i=0}^n)\\
=LSTM(\omega^{IMU}_n,a_n^{IMU},h_n)</script><p>$\hat{\mathbf{u}}_{n+1}$：每种运动状态的概率分布，是一个四维向量</p>
<p>$h_n$：神经网络的隐藏状态</p>
<p>然后将概率分数转为二进制向量，每种运动状态都有一个概率的阈值，超过则定为1：</p>
<script type="math/tex; mode=display">
\hat z_n=Threshold(\hat u_{n + 1})</script><h5 id="不变扩展卡尔曼滤波器（IEKF）"><a href="#不变扩展卡尔曼滤波器（IEKF）" class="headerlink" title="不变扩展卡尔曼滤波器（IEKF）"></a>不变扩展卡尔曼滤波器（IEKF）</h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108145009277.png" alt="image-20241108145009277"></p>
<p>使用IEKF执行<strong>IMU的测量与检测到的特定运动轮廓之间的融合</strong>，IEKF输出状态$\hat x_n$，包括IMU的姿态、速度、IMU偏置及其协方差</p>
<ol>
<li><p>IMU的状态</p>
<script type="math/tex; mode=display">
\mathbf{x}_{n}=\left(\mathbf{R}_{n},\ \mathbf{v}_{n}^\mathrm{w},\ \mathbf{p}_{n}^\mathrm{w},\ \mathbf{b}_{n}^{\omega},\ \mathbf{b}_{n}^\mathbf{a}\right)</script><p>包括机器人的姿态、速度和IMU的偏差。前面提到的机器人的各种运动状态，适用于右IEKF方法，将线性状态误差定义为：</p>
<script type="math/tex; mode=display">
\mathbf{e}_{n}={\begin{bmatrix}\boldsymbol{\xi}_{n}\\ \mathbf{e}_{n}^{\mathbf{b}}\end{bmatrix}}\sim{\mathcal{N}}\left(\mathbf{0},\mathbf{P}_{n}\right)</script><p>$e_n$误差状态向量：</p>
<ol>
<li>$\boldsymbol{\xi}_{n}$：描述导航系统状态的误差（例如姿态、速度、位置）的误差</li>
<li>$e_n^b$：表示传感器（IMU）偏置误差，包括加速度计和陀螺仪的偏置</li>
</ol>
<p>该误差向量服从0均值，协方差矩阵$P_n$（15*15）的正态分布，使用分块向量结构：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108150900454.png" alt="image-20241108150900454"></p>
<p>$\boldsymbol{\xi}_{n}$包括姿态误差$R_n$，速度误差$v_n$，位置误差$p_n$</p>
<p>$e_n^b$包括陀螺仪偏置误差和加速度计偏置误差</p>
<p>==下面的公式通过李群上的指数映射，将误差$\boldsymbol{\xi}_{n}$与估计状态$\hat{\chi}_{n}$组合，得到真实状态${\chi}_{n}$==</p>
<p>传感器的真实偏置可以分解为滤波器的估计值+误差</p>
<script type="math/tex; mode=display">
\begin{array}{l}\chi_{n}=\exp_{S E_{2}(3)}\left(\xi_{n}\right)\hat{\chi}_{n},\\\mathbf{b}_{n}=\mathbf{\hat{b}}_{n}+\mathbf{e}_{n}^{\mathbf{b}},\end{array}</script></li>
<li><p>传播步骤</p>
<p>如果没有检测到特定的运动状态，$\hat{z}_{n+1}^{\mathrm{\tiny{VEL}}}\;=\;0,\;\hat{z}_{n+1}^{\mathrm{\tiny{ANG}}}\;=\;0$，使用IMU模型获取状态$\hat x_{n+1}$，并使用Riccati方程得到协方差</p>
<script type="math/tex; mode=display">
\mathbf{P}_{n+1}=\mathbf{F}_{n}\mathbf{P}_{n}\mathbf{F}_{n}^{T}+\mathbf{G}_{n}\mathbf{Q}_{n}\mathbf{G}_{n}^{T}</script><p>如果检测到特定的运动状态</p>
<script type="math/tex; mode=display">
z_{n+1}^{\mathrm{vel}}=1\Rightarrow\begin{cases}\mathbf{v}_{n+1}^{\mathrm{w}}=\mathbf{v}_{n}^{w}\\ \mathbf{p}_{n+1}^{\mathrm{w}}=\mathbf{p}_{n}^{\mathrm{w}}\end{cases}
\\
\hat{z}_{n+1}^{\mathrm{ANG}}=1\Rightarrow\mathbf{R}_{n+1}=\mathbf{R}_{n}</script><p>每个运动轮廓产生下列伪测量：</p>
<script type="math/tex; mode=display">
\begin{array}{l}\mathbf{y}_{n+1}^{\mathrm{vel}}={\left[\begin{matrix}\mathbf{R}_{n+1}^{T}\mathbf{v}_{n+1}^{\mathrm{w}}\\ \mathbf{b}_{n+1}^{\mathbf{a}}-\mathbf{R}_{n+1}^{T}\end{matrix}\right.}\\\mathbf{y}_{n+1}^{\mathrm}={\begin{bmatrix}\mathbf{R}_{n+1}^{T}\mathbf{v}_{n+1}^{\mathbf{w}}\\ \mathbf{b}_{n+1}^{\mathbf{a}}-\mathbf{R}_{n+1}^{T}\mathbf{g}\end{bmatrix}}={\begin{bmatrix}\mathbf{0}\\ \mathbf{a}_{n}^{\mathrm}\end{bmatrix}}\,,\end{array}</script></li>
</ol>
<h4 id="Car-Datasets数据集"><a href="#Car-Datasets数据集" class="headerlink" title="Car Datasets数据集"></a>Car Datasets数据集</h4><h3 id="实验-2"><a href="#实验-2" class="headerlink" title="实验"></a>实验</h3><h2 id="RoNIN-Robust-Neural-Inertial-Navigation-in-the-Wild-Benchmark-Evaluations-and-New-Methods"><a href="#RoNIN-Robust-Neural-Inertial-Navigation-in-the-Wild-Benchmark-Evaluations-and-New-Methods" class="headerlink" title="RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, and New Methods"></a>RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, and New Methods</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105135448240.png" alt="image-20241105135448240"></p>
<h3 id="基本内容-3"><a href="#基本内容-3" class="headerlink" title="基本内容"></a>基本内容</h3><ol>
<li><strong>作者：</strong>Hang Yan∗ Sachini Herath ∗ Yasutaka Furukawa</li>
<li><strong>主页：</strong><a target="_blank" rel="noopener" href="https://ronin.cs.sfu.ca/">https://ronin.cs.sfu.ca/</a></li>
<li><strong>Github：</strong><a target="_blank" rel="noopener" href="https://github.com/Sachini/ronin">https://github.com/Sachini/ronin</a></li>
<li><strong>论文(2020 ICRA)：</strong><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4555200104986845185&amp;noteId=2565386194435307264">https://readpaper.com/pdf-annotate/note?pdfId=4555200104986845185&amp;noteId=2565386194435307264</a></li>
</ol>
<h3 id="摘要-3"><a href="#摘要-3" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>应用背景：<strong>仅</strong>从IMU传感器测量序列估计运动物体的<strong>位置和方向</strong>（不是IMU设备的位置和方向，而是运动物体的位置和方向）</li>
<li>面临问题：现有的惯性导航算法都需要一些不切实际的约束（IMU必须放到脚上，步骤计数方法假设IMU刚性附着在身体上，主体必须向前行走，使运动方向在设备坐标系中变为常数）</li>
<li>解决方案：<strong>数据驱动的方法</strong>，<strong>IMU传感器数据</strong>和<strong>地面轨迹真值</strong>允许运动参数的<strong>监督学习</strong></li>
<li>具体实现：</li>
<li>贡献<ol>
<li>新的Baseline，数据集为42.7h的IMU传感器数据，提供真实的3D轨迹</li>
<li>新的鲁棒神经惯导架构（RoNIN），在具有挑战性的运动情况中有显著改进</li>
<li>在三个benchmark上进行了<strong>定性和定量的评估</strong></li>
</ol>
</li>
</ol>
<h3 id="相关工作-3"><a href="#相关工作-3" class="headerlink" title="相关工作"></a>相关工作</h3><p><strong>对惯性导航算法进行归类：</strong></p>
<ol>
<li><p><strong>Physics-based （没有先验）</strong></p>
<p>IMU对比力双积分得到位置，对角速度积分得到偏转角。面临的问题则是双积分会导致误差漂移非常严重</p>
</li>
<li><p><strong>Heuristic priors（启发式先验）</strong></p>
<p>人的运动是比较规律的。试图找到这种运动规律，比如步骤计数（step couting）的方法，但是有约束，且鲁棒性很差</p>
<ol>
<li>IMU刚性附着于身体上</li>
<li>运动方向相对于IMU是固定的</li>
<li>运动距离跟步数是成正比的</li>
</ol>
</li>
<li><p><strong>Data-driven priors（数据驱动）</strong></p>
<p>两个工作</p>
<ol>
<li>RIDI（在载体坐标系中对速度向量进行回归分析，依靠传统传感器融合的方法来估计设备方向）</li>
<li>IONet（基于神经网络的方法，不依赖外部设备的方向信息，回归速度大小和方向变化）</li>
</ol>
</li>
</ol>
<h3 id="主要内容-3"><a href="#主要内容-3" class="headerlink" title="主要内容"></a>主要内容</h3><h4 id="RONIN数据集"><a href="#RONIN数据集" class="headerlink" title="RONIN数据集"></a>RONIN数据集</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105141659139.png" alt="image-20241105141659139"></p>
<ol>
<li>规模：42.7h，3个建筑，276个序列的IMU运动数据，轨迹和IMU数据均为200hz</li>
<li>100个人采集，3个安卓设备</li>
<li>真实自然，袋子内携带，口袋中，行走，坐立，徘徊等</li>
</ol>
<p><strong>采集方式：双设备采集，3D跟踪设备连接在身体上，IMU采集设备可以自由活动</strong>，受试者，在前5s内直接行走，将这个偏移角定为（身体运动方向和IMU运动方向的恒定偏移）</p>
<h4 id="RoNIN网络"><a href="#RoNIN网络" class="headerlink" title="RoNIN网络"></a>RoNIN网络</h4><ol>
<li>输入：<strong>航向不可知的坐标系下的</strong>IMU观测加速度和角速度</li>
<li>输出：当地导航坐标系下每帧的速度向量</li>
</ol>
<p>三个backbone：ResNet、LSTM、TCN，目的：从给定的IMU传感器历史数据的情况下回归速度向量</p>
<p><strong>两个关键设计:</strong></p>
<ol>
<li>定义输入和输出特征空间的坐标归一化</li>
<li>==即便是有噪声，鲁棒速度损失提高了信噪比==</li>
</ol>
<h5 id="坐标系归一化"><a href="#坐标系归一化" class="headerlink" title="坐标系归一化"></a>坐标系归一化</h5><ol>
<li>IMU传感器测量来自于本体坐标系，地面真实的运动轨迹来自当地导航坐标系，<strong>RoNIN使用航向不可知的坐标系来表示输入IMU和输出速度数据</strong></li>
<li>==假设用本体坐标系编码数据，本体坐标每帧数据变化，导致运动不一致（即使一个人完全相同的运动，目标速度会根据人拿手机的方式不一致）==</li>
<li>RoNIN使用于航向无关的坐标系（HACF），即z轴与重力对齐的任何坐标</li>
<li>在训练期间，每一步使用随机的HACF（通过在水平面上随机旋转真实的轨迹来实现，==IMU数据通过设备方向和相同的水平旋转转换为相同的HACF==）</li>
</ol>
<h5 id="Backbone网络结构"><a href="#Backbone网络结构" class="headerlink" title="Backbone网络结构"></a>Backbone网络结构</h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105145037343.png" alt="image-20241105145037343"></p>
<ol>
<li><p>ResNet18：采用ResNet18的1D版本，最后添加512个单元的MLP来回归2D向量</p>
<p>在第$i$帧处，网络将$i-200$帧到$i$帧的IMU输入数据（$200*6$的tensor），并在第$i$帧处产生速度向量</p>
<p>在测试时，对每5个帧进行预测，整合以输出运动轨迹</p>
</li>
<li><p>LSTM：采用堆叠的单向LSTM，通过连接双线性层的输出来丰富输入特征。3层，每层100个单元，为每个帧<strong>回归2D速度向量</strong>，添加额外的集成层来计算损失</p>
</li>
<li><p>TCN：6个残差块，分别有16、32、64、128、72、36个通道，==其中大小为3的卷积核导致253帧的感受野==</p>
</li>
</ol>
<h5 id="鲁棒速度损失"><a href="#鲁棒速度损失" class="headerlink" title="鲁棒速度损失"></a>鲁棒速度损失</h5><ol>
<li><p>Latent velocity loss（潜在速度损失）</p>
<p>LSTM/TCN 随时间回归一系列二维速度向量，添加一个集成层，<strong>该层对向量求和（LSTM/TCN超过400/253帧）</strong>，根据同一帧gt位置差异定义一个L2范数（这种差异强制每帧2D向量总和必须匹配位置差异）</p>
</li>
<li><p>Strided velocity loss（跨步速度损失）</p>
<p>ResNet学习预测200帧<strong>步幅的位置差异</strong>而不是速度，具体来说是计算第i帧的网络输出，与$P_i-P_{i-200}$差异的 MSE损失，其中$P_i$是全局帧i处的地面真实位置</p>
</li>
</ol>
<h4 id="RoNIN身体航向网络"><a href="#RoNIN身体航向网络" class="headerlink" title="RoNIN身体航向网络"></a>RoNIN身体航向网络</h4><ol>
<li>输入：<strong>航向不可知的坐标系下的</strong>IMU观测加速度和角速度</li>
<li>输出：当地导航坐标系下的每帧身体航向角的sin和cos</li>
</ol>
<ol>
<li>与位置回归不同，当主体静止，航向回归任务本质是模糊的。假设一个人坐在椅子上30s，仍需要及时访问IMU数据来估计身体的方向，因此借助LSTM来完成能够保持长内存的任务</li>
<li><strong>使用没有集成层的LSTM架构</strong>，让网络预测一个2D向量$(x,y)$，它们是每帧身体航向角的$sin$和$cos$,对gt真实的航向角的sin和cos使用MSE损失。还添加一个<strong>归一化的损失$||1-x^2-y^2||$，以确保是正确的三角函数值</strong></li>
</ol>
<h3 id="实验-3"><a href="#实验-3" class="headerlink" title="实验"></a>实验</h3><ol>
<li>设备：pytorch+1080Ti（12G）</li>
<li>对于ResNet：每10帧抽取一个包含400帧的样本，每个epoch随机打乱</li>
<li>对于LSTM：将序列展开为每k帧400步，k是50到150的随机整数</li>
<li>对于TCN：每过k帧提取400帧的样本，k是50到150的随机整数</li>
<li>Adam优化器，10个小时收敛</li>
</ol>
<p><strong>消融实验</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105153743566.png" alt="image-20241105153743566"></p>
<h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p><strong>在三个数据集上（RIDI 、OXIOD、RoNIN）对五种方法进行评估：</strong></p>
<p>Seen表示这部分测试数据也在训练集中，Unseen表示测试数据不包含在训练集中</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105152114452.png" alt="image-20241105152114452"></p>
<h4 id="位置评估"><a href="#位置评估" class="headerlink" title="位置评估"></a>位置评估</h4><ol>
<li>绝对轨迹误差（ATE）：估计轨迹和gt的均方根误差（RMSE）</li>
<li>相对轨迹误差（RTE）：固定时间间隔（1分钟）内的均方根误差</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105153000658.png" alt="image-20241105153000658"></p>
<h4 id="航向评估"><a href="#航向评估" class="headerlink" title="航向评估"></a>航向评估</h4><ol>
<li>sin和cos表示的均方误差（MSE）</li>
<li>航向的平均角度误差（MAE）</li>
</ol>
<p><strong>对于一些复杂的运动情况，错误会变得更大（最多 20 度），但通常小于 12 度</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105153419223.png" alt="image-20241105153419223"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241105153536239.png" alt="image-20241105153536239"></p>
<h2 id="AI-IMU-Dead-Reckoning"><a href="#AI-IMU-Dead-Reckoning" class="headerlink" title="AI-IMU Dead-Reckoning"></a>AI-IMU Dead-Reckoning</h2><p><a target="_blank" rel="noopener" href="https://github.com/mbrossar/ai-imu-dr">https://github.com/mbrossar/ai-imu-dr</a></p>
<h2 id="Neural-Inertial-Localization"><a href="#Neural-Inertial-Localization" class="headerlink" title="Neural Inertial Localization"></a>Neural Inertial Localization</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108182515119.png" alt="image-20241108182515119"></p>
<h3 id="基本内容-4"><a href="#基本内容-4" class="headerlink" title="基本内容"></a>基本内容</h3><ol>
<li><strong>作者：</strong>Sachini Herath1∗ David Caruso2 Chen Liu2 Yufan Chen2 Yasutaka Furukawa1，<strong>Simon Fraser University, BC, Canada</strong>  Reality Labs, Meta, Redmond, USA</li>
<li><strong>主页：</strong><a target="_blank" rel="noopener" href="https://sachini.github.io/niloc">https://sachini.github.io/niloc</a></li>
<li><strong>Github：</strong><a target="_blank" rel="noopener" href="https://github.com/Sachini/niloc">https://github.com/Sachini/niloc</a></li>
<li><strong>论文（2022 CVPR）：</strong><a target="_blank" rel="noopener" href="https://readpaper.com/pdf-annotate/note?pdfId=4607452768042491905&amp;noteId=2565490624417869056">https://readpaper.com/pdf-annotate/note?pdfId=4607452768042491905&amp;noteId=2565490624417869056</a></li>
</ol>
<h3 id="摘要-4"><a href="#摘要-4" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>应用背景：从IMU测量历史来估计绝对位置（室内定位）</li>
<li>面临问题：</li>
<li>解决方案：神经惯性定位（NILoc）</li>
<li>具体实现：使用神经惯导技术将<strong>IMU输入</strong>转为一系列<strong>速度向量序列</strong>（IMU观测-&gt;速度向量序列），使用transformer结构从<strong>速度向量序列</strong>找到设备的位置（速度向量序列-&gt;位置（高度是挑战））</li>
<li>贡献<ol>
<li>53个小时的惯性传感器数据和地面真实位置</li>
<li>现有方法sota</li>
</ol>
</li>
</ol>
<h3 id="相关工作-4"><a href="#相关工作-4" class="headerlink" title="相关工作"></a>相关工作</h3><ol>
<li>室内定位：Image-Based、WIFi、Bluetooth、IMU</li>
<li>惯性导航</li>
</ol>
<h3 id="主要内容-4"><a href="#主要内容-4" class="headerlink" title="主要内容"></a>主要内容</h3><h4 id="惯性定位问题"><a href="#惯性定位问题" class="headerlink" title="惯性定位问题"></a>惯性定位问题</h4><ol>
<li><p>输入：加速度+角速度，输出：带有时间戳的位置估计</p>
</li>
<li><p>指标：</p>
<ol>
<li>距离阈值（1、2、3、5米）内正确位置估计的比率</li>
<li>角度阈值（20 40度）内正确的速度方向的比率</li>
</ol>
<p><strong>位置比率是主要指标，方向比率衡量时间的一致性。</strong></p>
</li>
<li><p><strong>惯性重定位任务</strong></p>
<p>一种<strong>惯性重定位（re-localization）任务</strong>，与惯性定位（localization）有所不同。</p>
<p>在重新定位任务中，位置  （二维坐标）以及可选的运动方向是已知的。</p>
<p>这个任务模拟了一种场景：每隔几分钟利用 WiFi 获取一个全局位置，之后为了节省能源，<strong>使用惯性测量单元（IMU）传感器在 WiFi 定位间隔期间进行重新定位。</strong></p>
</li>
</ol>
<h4 id="惯性定位数据集"><a href="#惯性定位数据集" class="headerlink" title="惯性定位数据集"></a>惯性定位数据集</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108165955817.png" alt="image-20241108165955817"></p>
<ol>
<li>组成：两所大学建筑和一个办公空间53小时的运动轨迹数据，<strong>位置为二维坐标，没有垂直位移</strong></li>
<li>采集：200HZ</li>
</ol>
<h4 id="NILoc神经惯性定位"><a href="#NILoc神经惯性定位" class="headerlink" title="NILoc神经惯性定位"></a>NILoc神经惯性定位</h4><ol>
<li>输入：IMU对加速度积分后的<strong>相对速度向量</strong>，相对于本体坐标系</li>
<li>输出：<strong>位置分布概率图</strong></li>
</ol>
<p>NILoc不是从IMU测量来回归位置，而是先将IMU传感器数据转换为速度向量，<strong>任务的核心是将速度向量转换为位置估计</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108170423074.png" alt="image-20241108170423074"></p>
<p>两个基于Transformer的分支：</p>
<ol>
<li>速度分支（上）：编码一系列速度向量，时间卷积网络（TCN）压缩时间维度，增强感受野</li>
<li>自由位置回归分支（下）：编码一系列位置似然</li>
</ol>
<h5 id="速度分支"><a href="#速度分支" class="headerlink" title="速度分支"></a>速度分支</h5><p>该分支使用速度的历史数据来估计位置序列，包含三个模块：</p>
<ol>
<li><p><strong>TCN-based velocity compressor</strong></p>
<p>使用时间卷积网络TCN将速度序列长度压缩10倍，允许处理更长的运动历史</p>
<p>使用感受野为10的两层TCN，将长度为$T$的<strong>2维速度向量</strong>$\{v_t\}$，转换为长度为$\frac {T}{10}$的<strong>d维特征向量$\{v_t’\}$</strong></p>
<script type="math/tex; mode=display">
\{v_{1},v_{2},\cdot\cdot\cdot\cdot v_{T}\}\longrightarrow\{v_{1}^{\prime},v_{2}^{\prime},\cdot\cdot\cdot v_{T/10}^{\prime}\}.</script></li>
<li><p><strong>Transformer encoder</strong></p>
<p>将压缩的特征向量$\{v_t’\}$ 作为token，经过位置编码的特征向量为$f_t$，维度是$d’=1.5d$</p>
<script type="math/tex; mode=display">
f_t=[v_{t}^{\prime},\;\{\cos{(}w_{i}t{\big)}\},\{\sin{(}w_{i}t{)}\}]</script><p>$v_t’$是经过压缩后的d维特征向量，cos和sin是位置编码</p>
<p>$\omega_i$ 频率参数的计算：</p>
<script type="math/tex; mode=display">
w_{i}\quad=\quad\exp\frac{-l o g(10000)*i}{d^{\prime}}\ (i=1,2,\cdots d/4)</script></li>
</ol>
<p>   <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241108172509253.png" alt="image-20241108172509253"></p>
<p>   每个token的输出$e_t$也是$d’$维向量，encoder有2块自注意力网络，每块内有2个标准的encoder层和8路多头注意力，<strong>第一块生成的特征向量被传递给了另一个分支。</strong></p>
<ol>
<li><p><strong>Translation-aware location  decoder</strong></p>
<p>encoder传入的$d’$维特征$e_t$</p>
<ol>
<li><p>$e_t$被重新排列为类似于图像的3D tensor  $[W, H, C]$</p>
<p>（这图像特征体（3D张量）是场景绑定的，需要根据不同的场景做出变换，原文也说了<strong>在ABC三个不同的场景这里分别是不同的</strong>：The dimensions (width,height,channels) are <strong>24x18x1, 16x44x1, and 14x48x1</strong> for the three scenes A, B, and C, respectively）</p>
</li>
<li><p>通过具有转置卷积的3层全卷积解码器进行上采样</p>
<p>转置卷积可以放大特征图的空间分辨率，从特征张量中恢复出更细粒度的空间信息</p>
</li>
<li><p>Translation-aware卷积</p>
<p>为1×1的卷积，该卷积层的参数不在像素之间共享（不同位置的卷积核是独立的），<strong>这一特性允许网络在每个位置上捕获局部的信息</strong>。比如某些位置上可能无法出现目标或目标经常出现在特定区域</p>
</li>
<li><p>生成2D概率分布图</p>
<p>网络输出一个2D概率图$L_t(x,y)$，表示时间步$t$的位置信息</p>
<p>概率图大小为$[W,H]$，概率值解释为在$(x,y)$位置上目标出现的可能性</p>
</li>
</ol>
</li>
</ol>
<h5 id="自回归位置分支"><a href="#自回归位置分支" class="headerlink" title="自回归位置分支"></a>自回归位置分支</h5><p>位置分支结合了速度分支和先验位置似然的速度特征，这些特征来自于它过去的推理or外部额外的位置信息比如WIFI</p>
<ol>
<li>使用卷积神经网络ConvNet，将每个$W<em>H$的似然图转换为$d’$维的特征向量，<em>*然后全部拆分</em></em></li>
<li>使用相同的位置编码，维度为$d’$，将位置编码添加到特征向量中</li>
<li>在每个自注意力层之后，通过交叉注意力从速度分支注入速度特征</li>
</ol>
<h4 id="合成数据生成"><a href="#合成数据生成" class="headerlink" title="合成数据生成"></a>合成数据生成</h4><p>Transformer需要大量数据，在不同的时间窗口上裁剪数据，当训练数据不够时，采用下面三种方法生成：</p>
<ol>
<li>计算训练轨迹的可能性图</li>
<li>从高似然区域随机选择一对位置</li>
<li>解决优化问题以产生平滑并通过高似然区域的轨迹</li>
</ol>
<h3 id="实验-4"><a href="#实验-4" class="headerlink" title="实验"></a>实验</h3><ol>
<li>Loss：交叉熵损失，gt是真实轨迹的二值图像</li>
</ol>
<h2 id="Deep-Learning-Based-Speed-Estimation-for-Constraining-Strapdown-Inertial-Navigation-on-Smartphones"><a href="#Deep-Learning-Based-Speed-Estimation-for-Constraining-Strapdown-Inertial-Navigation-on-Smartphones" class="headerlink" title="Deep Learning Based Speed Estimation for Constraining Strapdown Inertial Navigation on Smartphones"></a>Deep Learning Based Speed Estimation for Constraining Strapdown Inertial Navigation on Smartphones</h2><p><a target="_blank" rel="noopener" href="https://github.com/AaltoVision/deep-speed-constrained-ins">https://github.com/AaltoVision/deep-speed-constrained-ins</a></p>
<h2 id="TLIO-Tight-Learned-Inertial-Odometry"><a href="#TLIO-Tight-Learned-Inertial-Odometry" class="headerlink" title="TLIO: Tight Learned Inertial Odometry"></a>TLIO: Tight Learned Inertial Odometry</h2><p><a target="_blank" rel="noopener" href="https://cathias.github.io/TLIO/">https://cathias.github.io/TLIO/</a></p>
<h2 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h2><h3 id="基本内容-5"><a href="#基本内容-5" class="headerlink" title="基本内容"></a>基本内容</h3><ol>
<li><strong>作者：</strong></li>
<li><strong>主页：</strong></li>
<li><strong>Github：</strong></li>
<li><strong>论文：</strong></li>
</ol>
<h3 id="摘要-5"><a href="#摘要-5" class="headerlink" title="摘要"></a>摘要</h3><ol>
<li>应用背景：</li>
<li>面临问题：</li>
<li>解决方案：</li>
<li>具体实现：</li>
<li>贡献<ol>
<li></li>
</ol>
</li>
</ol>
<h3 id="相关工作-5"><a href="#相关工作-5" class="headerlink" title="相关工作"></a>相关工作</h3><h3 id="主要内容-5"><a href="#主要内容-5" class="headerlink" title="主要内容"></a>主要内容</h3><h3 id="实验-5"><a href="#实验-5" class="headerlink" title="实验"></a>实验</h3></article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/avatar.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/avatar.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">11andyy</div><div class="post-copyright__author_desc">生活明朗，万物可爱</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/')">PaperReading</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="/img/wechatpay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/wechatpay.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=PaperReading&amp;url=https://11andyy.github.io/2024/10/20/WeeklyReport/PaperReading/&amp;pic=https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://11andyy.github.io" target="_blank">11的Blog</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/%E8%AE%BA%E6%96%87/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>论文<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/%E7%BB%84%E4%BC%9A%E6%B1%87%E6%8A%A5/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>组会汇报<span class="tagsPageCount">2</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2024/10/20/WeeklyReport/%E5%91%A8%E8%AE%B0/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">周报</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2024/10/20/WeeklyReport/%E5%91%A8%E8%AE%B0/" title="周报"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-10-20</div><div class="title">周报</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">本博客建立的初衷是为了记录一路走来学习的计算机专业知识,方便之后复习与查看,<b style="color:#fff">起于此，但不止于此</b>,勤能补拙，相信一点点的积累最后汇聚成海!</div><div style="line-height:1.38;margin:0.6rem 0;text-align:justify;color:rgba(255, 255, 255, 0.8);">希望我的这个小小的计划,可以真正地帮助到实力强大的你!</div></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">11andyy</h1><div class="author-info__desc">生活明朗，万物可爱</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/11andyy" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><a class="social-icon faa-parent animated-hover" href="https://space.bilibili.com/372204786" target="_blank" title="BiliBili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a></div></div></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bullhorn anzhiyu-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来看我的博客鸭~</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA%E5%AE%9A%E4%BD%8D"><span class="toc-number">1.</span> <span class="toc-text">基于神经网络的惯性导航定位</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#IONet-Learning-to-Cure-the-Curse-of-Drift-in-Inertial-Odometry"><span class="toc-number">1.1.</span> <span class="toc-text">IONet: Learning to Cure the Curse of Drift in Inertial Odometry</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AE%B9"><span class="toc-number">1.1.1.</span> <span class="toc-text">基本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.1.3.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9"><span class="toc-number">1.1.4.</span> <span class="toc-text">主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%83%AF%E6%80%A7%E8%B7%9F%E8%B8%AA"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">惯性跟踪</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8C%89%E7%AA%97%E5%8F%A3%E5%88%87%E5%88%86%E6%83%AF%E6%80%A7%E6%95%B0%E6%8D%AE"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">按窗口切分惯性数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%8D%E7%A7%BB"><span class="toc-number">1.1.4.2.1.</span> <span class="toc-text">位移</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%81%8F%E8%88%AA%E8%A7%92"><span class="toc-number">1.1.4.2.2.</span> <span class="toc-text">偏航角</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6"><span class="toc-number">1.1.4.3.</span> <span class="toc-text">深度学习网络框架</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.1.5.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.1.5.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.5.2.</span> <span class="toc-text">训练</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RIDI-Robust-IMU-Double-Integration"><span class="toc-number">1.2.</span> <span class="toc-text">RIDI: Robust IMU Double Integration</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AE%B9-1"><span class="toc-number">1.2.1.</span> <span class="toc-text">基本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81-1"><span class="toc-number">1.2.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-1"><span class="toc-number">1.2.3.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9-1"><span class="toc-number">1.2.4.</span> <span class="toc-text">主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9D%90%E6%A0%87%E7%B3%BB"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">坐标系</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E5%9B%9E%E5%BD%92%E9%80%9F%E5%BA%A6"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">学习回归速度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%AD%A3%E5%8A%A0%E9%80%9F%E5%BA%A6%E8%AF%AF%E5%B7%AE"><span class="toc-number">1.2.4.3.</span> <span class="toc-text">修正加速度误差</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-1"><span class="toc-number">1.2.5.</span> <span class="toc-text">实验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RINS-W-Robust-Inertial-Navigation-System-on-Wheels"><span class="toc-number">1.3.</span> <span class="toc-text">RINS-W: Robust Inertial Navigation System on Wheels</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AE%B9-2"><span class="toc-number">1.3.1.</span> <span class="toc-text">基本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81-2"><span class="toc-number">1.3.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-2"><span class="toc-number">1.3.3.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9-2"><span class="toc-number">1.3.4.</span> <span class="toc-text">主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BC%A0%E6%84%9F%E5%99%A8%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">惯性导航系统和传感器模型</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA%E7%B3%BB%E7%BB%9F"><span class="toc-number">1.3.4.1.1.</span> <span class="toc-text">惯性导航系统</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#IMU%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.4.1.2.</span> <span class="toc-text">IMU模型</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BD%AE%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%BF%90%E5%8A%A8%E7%89%B9%E6%80%A7"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">轮式机器人运动特性</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BD%AE%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%BF%90%E5%8A%A8%E8%BD%AE%E5%BB%93"><span class="toc-number">1.3.4.2.1.</span> <span class="toc-text">轮式机器人运动轮廓</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%BD%AE%E5%BC%8F%E6%9C%BA%E5%99%A8%E4%BA%BA%E8%BF%90%E5%8A%A8%E8%BD%AE%E5%BB%93%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.3.4.2.2.</span> <span class="toc-text">轮式机器人运动轮廓的选择</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RINS-W%E7%AE%97%E6%B3%95"><span class="toc-number">1.3.4.3.</span> <span class="toc-text">RINS-W算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%89%B9%E5%AE%9A%E7%9A%84%E8%BF%90%E5%8A%A8%E8%BD%AE%E5%BB%93%E6%A3%80%E6%B5%8B%E5%99%A8%EF%BC%88LSTM%EF%BC%89"><span class="toc-number">1.3.4.3.1.</span> <span class="toc-text">特定的运动轮廓检测器（LSTM）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%8D%E5%8F%98%E6%89%A9%E5%B1%95%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E5%99%A8%EF%BC%88IEKF%EF%BC%89"><span class="toc-number">1.3.4.3.2.</span> <span class="toc-text">不变扩展卡尔曼滤波器（IEKF）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Car-Datasets%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.3.4.4.</span> <span class="toc-text">Car Datasets数据集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-2"><span class="toc-number">1.3.5.</span> <span class="toc-text">实验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RoNIN-Robust-Neural-Inertial-Navigation-in-the-Wild-Benchmark-Evaluations-and-New-Methods"><span class="toc-number">1.4.</span> <span class="toc-text">RoNIN: Robust Neural Inertial Navigation in the Wild: Benchmark, Evaluations, and New Methods</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AE%B9-3"><span class="toc-number">1.4.1.</span> <span class="toc-text">基本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81-3"><span class="toc-number">1.4.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-3"><span class="toc-number">1.4.3.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9-3"><span class="toc-number">1.4.4.</span> <span class="toc-text">主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RONIN%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">RONIN数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RoNIN%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">RoNIN网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9D%90%E6%A0%87%E7%B3%BB%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">1.4.4.2.1.</span> <span class="toc-text">坐标系归一化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Backbone%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84"><span class="toc-number">1.4.4.2.2.</span> <span class="toc-text">Backbone网络结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%B2%81%E6%A3%92%E9%80%9F%E5%BA%A6%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.4.4.2.3.</span> <span class="toc-text">鲁棒速度损失</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RoNIN%E8%BA%AB%E4%BD%93%E8%88%AA%E5%90%91%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">RoNIN身体航向网络</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-3"><span class="toc-number">1.4.5.</span> <span class="toc-text">实验</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.6.</span> <span class="toc-text">评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BD%8D%E7%BD%AE%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.6.1.</span> <span class="toc-text">位置评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%88%AA%E5%90%91%E8%AF%84%E4%BC%B0"><span class="toc-number">1.4.6.2.</span> <span class="toc-text">航向评估</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AI-IMU-Dead-Reckoning"><span class="toc-number">1.5.</span> <span class="toc-text">AI-IMU Dead-Reckoning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Neural-Inertial-Localization"><span class="toc-number">1.6.</span> <span class="toc-text">Neural Inertial Localization</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AE%B9-4"><span class="toc-number">1.6.1.</span> <span class="toc-text">基本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81-4"><span class="toc-number">1.6.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-4"><span class="toc-number">1.6.3.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9-4"><span class="toc-number">1.6.4.</span> <span class="toc-text">主要内容</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%83%AF%E6%80%A7%E5%AE%9A%E4%BD%8D%E9%97%AE%E9%A2%98"><span class="toc-number">1.6.4.1.</span> <span class="toc-text">惯性定位问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%83%AF%E6%80%A7%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.6.4.2.</span> <span class="toc-text">惯性定位数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NILoc%E7%A5%9E%E7%BB%8F%E6%83%AF%E6%80%A7%E5%AE%9A%E4%BD%8D"><span class="toc-number">1.6.4.3.</span> <span class="toc-text">NILoc神经惯性定位</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%80%9F%E5%BA%A6%E5%88%86%E6%94%AF"><span class="toc-number">1.6.4.3.1.</span> <span class="toc-text">速度分支</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%9B%9E%E5%BD%92%E4%BD%8D%E7%BD%AE%E5%88%86%E6%94%AF"><span class="toc-number">1.6.4.3.2.</span> <span class="toc-text">自回归位置分支</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%88%E6%88%90%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90"><span class="toc-number">1.6.4.4.</span> <span class="toc-text">合成数据生成</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-4"><span class="toc-number">1.6.5.</span> <span class="toc-text">实验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Deep-Learning-Based-Speed-Estimation-for-Constraining-Strapdown-Inertial-Navigation-on-Smartphones"><span class="toc-number">1.7.</span> <span class="toc-text">Deep Learning Based Speed Estimation for Constraining Strapdown Inertial Navigation on Smartphones</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TLIO-Tight-Learned-Inertial-Odometry"><span class="toc-number">1.8.</span> <span class="toc-text">TLIO: Tight Learned Inertial Odometry</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Template"><span class="toc-number">1.9.</span> <span class="toc-text">Template</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%86%85%E5%AE%B9-5"><span class="toc-number">1.9.1.</span> <span class="toc-text">基本内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81-5"><span class="toc-number">1.9.2.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-5"><span class="toc-number">1.9.3.</span> <span class="toc-text">相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9-5"><span class="toc-number">1.9.4.</span> <span class="toc-text">主要内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C-5"><span class="toc-number">1.9.5.</span> <span class="toc-text">实验</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/10/20/WeeklyReport/PaperReading/" title="PaperReading"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PaperReading"/></a><div class="content"><a class="title" href="/2024/10/20/WeeklyReport/PaperReading/" title="PaperReading">PaperReading</a><time datetime="2024-10-20T03:58:03.000Z" title="发表于 2024-10-20 11:58:03">2024-10-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/20/WeeklyReport/%E5%91%A8%E8%AE%B0/" title="周报"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241026155828470.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="周报"/></a><div class="content"><a class="title" href="/2024/10/20/WeeklyReport/%E5%91%A8%E8%AE%B0/" title="周报">周报</a><time datetime="2024-10-20T03:58:03.000Z" title="发表于 2024-10-20 11:58:03">2024-10-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/16/AutonomousDriving/GNSS/" title="GNSS与惯性及多传感器组合导航系统原理"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241018181640482.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="GNSS与惯性及多传感器组合导航系统原理"/></a><div class="content"><a class="title" href="/2024/10/16/AutonomousDriving/GNSS/" title="GNSS与惯性及多传感器组合导航系统原理">GNSS与惯性及多传感器组合导航系统原理</a><time datetime="2024-10-16T04:02:03.000Z" title="发表于 2024-10-16 12:02:03">2024-10-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/06/AutonomousDriving/PathPlanning/" title="路径规划"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241006150221350.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="路径规划"/></a><div class="content"><a class="title" href="/2024/10/06/AutonomousDriving/PathPlanning/" title="路径规划">路径规划</a><time datetime="2024-10-06T07:02:03.000Z" title="发表于 2024-10-06 15:02:03">2024-10-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/06/Tools/CMake/" title="CMake"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/11andyy/Pic0@master/img/image-20241006084123871.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CMake"/></a><div class="content"><a class="title" href="/2024/10/06/Tools/CMake/" title="CMake">CMake</a><time datetime="2024-10-06T00:02:03.000Z" title="发表于 2024-10-06 08:02:03">2024-10-06</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v7.3.0" title="博客框架为Hexo_v7.3.0"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Frame-Hexo.svg" alt="博客框架为Hexo_v7.3.0"/></a><a class="github-badge" target="_blank" href="https://blog.anheyu.com/" style="margin-inline:5px" data-title="本站使用AnZhiYu主题" title="本站使用AnZhiYu主题"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.9/img/Theme-AnZhiYu-2E67D3.svg" alt="本站使用AnZhiYu主题"/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title="本站项目由Github托管"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.1.5/img/badge/Source-Github.svg" alt="本站项目由Github托管"/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://npm.elemecdn.com/anzhiyu-blog@2.2.0/img/badge/Copyright-BY-NC-SA.svg" alt="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"/></a></p></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2021 - 2024 By <a class="footer-bar-link" href="/" title="11andyy" target="_blank">11andyy</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">27</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">44</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">7</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://index.anheyu.com/" title="个人主页"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2748ef34.jpg" alt="个人主页"/><span class="back-menu-item-text">个人主页</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/07/23/64bc72c75319d.png" alt="博客"/><span class="back-menu-item-text">博客</span></a><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/13/64d8c2653332e.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/408/" style="font-size: 0.88rem;">408<sup>4</sup></a><a href="/tags/Anaconda/" style="font-size: 0.88rem;">Anaconda<sup>1</sup></a><a href="/tags/C/" style="font-size: 0.88rem;">C++<sup>1</sup></a><a href="/tags/CMake/" style="font-size: 0.88rem;">CMake<sup>1</sup></a><a href="/tags/Carla/" style="font-size: 0.88rem;">Carla<sup>1</sup></a><a href="/tags/Docker/" style="font-size: 0.88rem;">Docker<sup>1</sup></a><a href="/tags/GNSS/" style="font-size: 0.88rem;">GNSS<sup>1</sup></a><a href="/tags/Git/" style="font-size: 0.88rem;">Git<sup>1</sup></a><a href="/tags/Latex/" style="font-size: 0.88rem;">Latex<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem;">Linux<sup>1</sup></a><a href="/tags/Pipe/" style="font-size: 0.88rem;">Pipe<sup>1</sup></a><a href="/tags/Python/" style="font-size: 0.88rem;">Python<sup>1</sup></a><a href="/tags/Ros/" style="font-size: 0.88rem;">Ros<sup>1</sup></a><a href="/tags/SCP/" style="font-size: 0.88rem;">SCP<sup>1</sup></a><a href="/tags/SSH/" style="font-size: 0.88rem;">SSH<sup>1</sup></a><a href="/tags/Tmux/" style="font-size: 0.88rem;">Tmux<sup>2</sup></a><a href="/tags/Vim/" style="font-size: 0.88rem;">Vim<sup>2</sup></a><a href="/tags/WSL/" style="font-size: 0.88rem;">WSL<sup>1</sup></a><a href="/tags/easyRL%E8%98%91%E8%8F%87%E4%B9%A6/" style="font-size: 0.88rem;">easyRL蘑菇书<sup>1</sup></a><a href="/tags/%E5%9B%BE%E5%BA%8A/" style="font-size: 0.88rem;">图床<sup>1</sup></a><a href="/tags/%E5%AE%9E%E7%94%A8%E6%95%99%E7%A8%8B/" style="font-size: 0.88rem;">实用教程<sup>4</sup></a><a href="/tags/%E5%AF%BC%E8%88%AA%E5%AE%9A%E4%BD%8D/" style="font-size: 0.88rem;">导航定位<sup>1</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7/" style="font-size: 0.88rem;">工具<sup>1</sup></a><a href="/tags/%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/" style="font-size: 0.88rem;">工具配置<sup>1</sup></a><a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/" style="font-size: 0.88rem;">强化学习<sup>1</sup></a><a href="/tags/%E6%83%AF%E6%80%A7%E5%AF%BC%E8%88%AA/" style="font-size: 0.88rem;">惯性导航<sup>1</sup></a><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 0.88rem;">操作系统<sup>2</sup></a><a href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" style="font-size: 0.88rem;">数据结构<sup>1</sup></a><a href="/tags/%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%B7%A5%E5%85%B7/" style="font-size: 0.88rem;">文本编辑工具<sup>2</sup></a><a href="/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/" style="font-size: 0.88rem;">服务器配置<sup>1</sup></a><a href="/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 0.88rem;">机器人操作系统<sup>1</sup></a><a href="/tags/%E6%9D%8E%E8%A7%85%E9%9D%92%E4%BA%BA%E5%83%8F/" style="font-size: 0.88rem;">李觅青人像<sup>1</sup></a><a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B7%A5%E5%85%B7/" style="font-size: 0.88rem;">深度学习工具<sup>5</sup></a><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size: 0.88rem;">算法<sup>1</sup></a><a href="/tags/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/" style="font-size: 0.88rem;">编程语言<sup>1</sup></a><a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/" style="font-size: 0.88rem;">自动驾驶<sup>4</sup></a><a href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E4%BB%BF%E7%9C%9F/" style="font-size: 0.88rem;">自动驾驶仿真<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/" style="font-size: 0.88rem;">计算机组成原理<sup>1</sup></a><a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 0.88rem;">计算机网络<sup>1</sup></a><a href="/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/" style="font-size: 0.88rem;">路径规划<sup>1</sup></a></div></div><hr/></div></div><div id="keyboard-tips"><div class="keyboardTitle">博客快捷键</div><div class="keybordList"><div class="keybordItem"><div class="keyGroup"><div class="key">shift K</div></div><div class="keyContent"><div class="content">关闭快捷键功能</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift A</div></div><div class="keyContent"><div class="content">打开/关闭中控台</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift M</div></div><div class="keyContent"><div class="content">播放/暂停音乐</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift D</div></div><div class="keyContent"><div class="content">深色/浅色显示模式</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift S</div></div><div class="keyContent"><div class="content">站内搜索</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift R</div></div><div class="keyContent"><div class="content">随机访问</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift H</div></div><div class="keyContent"><div class="content">返回首页</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift F</div></div><div class="keyContent"><div class="content">友链鱼塘</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift L</div></div><div class="keyContent"><div class="content">友链页面</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift P</div></div><div class="keyContent"><div class="content">关于本站</div></div></div><div class="keybordItem"><div class="keyGroup"><div class="key">shift I</div></div><div class="keyContent"><div class="content">原版/本站右键菜单</div></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="chat-btn" type="button" title="聊天"><i class="anzhiyufont anzhiyu-icon-comment-sms"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("04/01/2021 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2021 By 安知鱼 V1.6.12",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 11andyy 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.cbd.int/mathjax@3.2.2/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script src="/js/anzhiyu/right_click_menu.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><script>(() => {
  const isChatBtn = true
  const isChatHideShow = false

  if (isChatBtn) {
    const close = () => {
      Chatra('minimizeWidget')
      Chatra('hide')
    }

    const open = () => {
      Chatra('openChat', true)
      Chatra('show')
    }

    window.ChatraSetup = {
      startHidden: true
    }
  
    window.chatBtnFn = () => {
      const isShow = document.getElementById('chatra').classList.contains('chatra--expanded')
      isShow ? close() : open()
    }
  } else if (isChatHideShow) {
    window.chatBtn = {
      hide: () => {
        Chatra('hide')
      },
      show: () => {
        Chatra('show')
      }
    }
  }

  (function(d, w, c) {
    w.ChatraID = 'XuXAxHxmtsvpjunNh'
    var s = d.createElement('script')
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments)
    }
    s.async = true
    s.src = 'https://call.chatra.io/chatra.js'
    if (d.head) d.head.appendChild(s)
  })(document, window, 'Chatra')

})()</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>